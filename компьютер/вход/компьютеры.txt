‘‘[Y]ou...fellows ought to go back and change your program entirely, stop this . . . foolishness with Eckert and Mauchly.’’ That was the opinion of Howard Aiken, Harvard mathematician and builder of the Mark I calculator, expressed to Edward Cannon of the U.S. National Bureau of Standards in 1948. Aiken made that remark as a member of a National Research Council committee that had just recommended that the Bureau of Standards not support J. Presper Eckert and John Mauchly’s proposal to make and sell electronic computers (figure 1.1). In Aiken’s view, a commercial market would never develop; in the United States there was a need for perhaps for five or six such machines, but no more.1
Howard Aiken was wrong. There turned out to be a market for millions of electronic digital computers by the 1990s, many of them personal devices that fit easily into a briefcase. That would not have happened were it not for advances in solid state physics, which provided a way of putting the circuits of a computer on a few chips of silicon. Nevertheless, the nearly ubiquitous computers of the 1990s are direct descendants of what Eckert and Mauchly hoped to commercialize in the late 1940s.
The Eckert-Mauchly Computer Corporation did not remain an inde- pendent entity for long; it was absorbed by Remington Rand and became a division of that business-machine company. Eckert and Mauchly’s computer, the UNIVAC, was a technical masterpiece but was eclipsed in the market by computers made by Remington-Rand’s competitor, IBM. So one could say that they were indeed foolish in their underestimation of the difficulties of commercializing their inven- tion. What was not foolish was their vision, not only of how to design and build a computer but also of how a society might benefit from large numbers of them.
14 Chapter 1

Figure 1.1
Staff of the Eckert-Mauchly Computer Corporation, ca. 1948, in Philadelphia. Eckert is at the lower left; Mauchly at the lower right. The apparatus behind them is a portion of the BINAC, which the company was building for the Northrop Aircraft Company. Back row, left to right: Albert Auerbach, Jean Bartik, Marvin Jacoby, John Sims, Louis Wilson, Robert Shaw, Gerald Smoliar. Front row : J. Presper Eckert, Frazier Welsh, James Wiener, Bradford Sheppard, John Mauchly. (Source : Unisys Corporation.)
Computing after 1945 is a story of people who at critical moments redefined the nature of the technology itself. In doing so they opened up computing to new markets, new applications, and a new place in the social order. Eckert and Mauchly were the first of many who effected such a transformation. They took an expensive and fragile scientific instrument, similar to a cyclotron, and turned it into a product that could be manufactured and sold, if only in small quantities.2 In the mid- 1950s the IBM Corporation developed a line of products that met the information-handling needs of American businesses. A decade later, alumni from MIT’s Project Whirlwind turned the computer into a device that one interacted with, a tool with which to augment one’s intellectual efforts. In the mid-1970s, a group of hobbyists and enthusiasts trans- formed it into a personal appliance. Around 1980, it was transformed
The Advent of Commercial Computing, 1945–1956 15
from a piece of specialized hardware to a standardized consumer product defined by its now-commercialized software. In the 1990s it is going through another transformation, turning into an agent of a worldwide nexus, a communications medium. The ‘‘computer age’’— really a series of ‘‘computer ages’’—was not just invented; it was willed into existence by people who wanted it to happen. This process of reinvention and redefinition is still going on.
The UNIVAC in Context
Eckert and Mauchly brought on the first of these transformations in 1951 with a computer they called ‘‘UNIVAC.’’ The acronym came from ‘‘Universal Automatic Computer,’’ a name that they chose carefully. ‘‘Universal’’ implied that it could solve problems encountered by scientists, engineers, and businesses. ‘‘Automatic’’ implied that it could solve complex problems without requiring constant human intervention or judgment, as existing techniques required. Before discussing its creation, one needs to understand how computing work was being done in different areas and why a single machine, a UNIVAC, could serve them equally well. One must also understand how existing calculating machines, the results of decades of refinement and use, were deficient. It was that deficiency that made room for the UNIVAC, which broke with past practices in many ways.
Punched Cards
During the Second World War, Eckert and Mauchly designed and built the ENIAC at the University of Pennsylvania’s Moore School of Electrical Engineering. The ENIAC was an electronic calculator that inaugurated the era of digital computing in the United States. Its purpose was to calculate firing tables for the U.S. Army, a task that involved the repetitive solution of complex mathematical expressions. It was while working on this device that they conceived of something that had a more universal appeal.
The flow of information through the UNIVAC reflected Eckert and Mauchly’s background in physics and engineering. That is, the flow of instructions and data in the UNIVAC mirrored the way humans using mechanical calculators, books of tables, and pencil and paper performed scientific calculations.3 Although the vacuum tube circuits might have appeared novel, a scientist or engineer would not have found anything unusual in the way a UNIVAC attacked a problem.
16 Chapter 1
However, those engaged in business calculations, customers Eckert and Mauchly also wanted their machine to serve, would have found the UNIVAC’s method of processing unusual.4 In the late nineteenth century, many businesses adopted a practice that organized work using a punched card machine; typically an ensemble of three to six different punched-card devices would comprise an installation.5 To replace these machines with a computer, the business had also to adopt the UNIVAC’s way of processing information. Punched-card machines are often called ‘‘unit record equipment.’’ With them, all relevant information about a particular entity (e.g., a sales transaction) is encoded on a single card that can serve multiple uses by being run through different pieces of equipment; for example, to count, sort, tabulate, or print on a particular set of columns.6 Historical accounts of punched-card machinery have described in great detail the functioning of the individual machines. More relevant is the ‘‘architecture’’ of the entire room—including the people in it—that comprised a punched-card installation, since it was that room, not the individual machines, that the electronic computer eventually replaced.
In a typical punched-card installation, the same operation was performed on all the records in a file as a deck of cards went through a tabulator or other machine (figure 1.2). The UNIVAC and its successors could operate that way, but they could also perform a long sequence of operations on a single datum before fetching the next record from memory. In punched-card terms, that would require carrying a ‘‘deck’’ of a single card around the room—hardly an economical use of the machinery or the people. Processing information gathered into a deck of cards was entrenched into business practices by the mid-1930s, and reinforced by the deep penetration of the punched- card equipment salesmen into the accounting offices of their customers.7
By the 1930s a few scientists, in particular astronomers, began using punched-card equipment for scientific problems. They found that it made sense to perform sequences of operations on each datum, since often the next operation depended on the results of the previous one. One such person was Wallace Eckert (no relation to J. Presper Eckert), who with the aid of IBM established the Thomas J. Watson Computing Bureau at Columbia University in New York in 1934. In 1940 he summarized his work in an influential book, Punched Card Methods in Scientific Computation. In it, he explained that punched-card machines ‘‘are all designed for computation where each operation is done on
The Advent of Commercial Computing, 1945–1956 17

Figure 1.2
IBM punched card. From IBM Corporation, ‘‘IBM Data Processing Functions,’’ Brochure 224-8208-5, ca. 1963. (Source : IBM Corporation.)
18 Chapter 1
many cards before the next operation is begun.’’8 He emphasized how one could use existing equipment to do scientific work, but he stated that it was not worth the ‘‘expense and delay involved’’ in building specialized machines to solve scientific problems.9 A decade later, that was precisely what J. Presper Eckert and John Mauchly were proposing to do—go to great expense and effort to create a ‘‘universal’’ machine that could handle both business and scientific problems.
Ironically, Wallace Eckert was among the first to venture away from traditional punched-card practices and toward one more like the digital computers that would later appear. Despite his recommendation against building specialized equipment, he did have a device called a control switch designed at his laboratory. He installed this switch between the multiplier, tabulator, and summary punch. Its function was to allow short sequences of operations (up to 12) to be performed on a single card before the next card was read.10 Following his advice, IBM built and installed two specially built punched-card machines at the U.S. Army’s Ballistic Research Laboratory at Aberdeen, Maryland. IBM called these machines the ‘‘Aberdeen Relay Calculators’’; they were later known as the PSRC, for ‘‘Pluggable Sequence Relay Calculator.’’11
In late 1945, three more were built for other military labs, and these were even more complex. During the time one of these machines read a card, it could execute a sequence of up to forty-eight steps. More complex sequences-within-sequences were also possible.12 One compu- ter scientist later noted that this method of programming demanded ‘‘the kind of detailed design of parallel subsequencing that one sees nowadays at the microprogramming level of some computers.’’13 When properly programmed, the machines were faster than any other nonelectronic calculator. Even after the ENIAC was completed and installed and moved from Philadelphia to Aberdeen, the Ballistic Research Lab had additional Relay Calculators built. They were still in use in 1952, by which time the BRL not only had the ENIAC but also the EDVAC, the ORDVAC (both electronic computers), an IBM Card Programmed Calculator (described next), and the Bell Labs Model V, a very large programmable relay calculator.14
The Card-Programmed Calculator
The Aberdeen Relay Calculators never became a commercial product, but they reveal an attempt to adapt existing equipment to post–World War II needs, rather than take a revolutionary approach, such as the
The Advent of Commercial Computing, 1945–1956 19
UNIVAC. There were also other punched-card devices that represented genuine commercial alternatives to Eckert and Mauchly’s proposed invention. In 1935 IBM introduced a multiplying punch (the Model 601); these soon became popular for scientific or statistical work. In 1946 IBM introduced an improved model, the 603, the first commercial IBM product to use vacuum tubes for calculating. Two years later IBM replaced it with the 604, which not only used tubes but also incorporated the sequencing capability pioneered by the Aberdeen machines. Besides the usual plugboard control common to other punched-card equip- ment, it could execute up to 60 steps for each reading of a card and setting of the plugboard.15 The 604 and its successor, the IBM 605, became the mainstays of scientific computing at many installations until reliable commercial computers became available in the mid 1950s. It was one of IBM’s most successful products during that era: over 5,000 were built between 1948 and 1958.16
One of IBM’s biggest engineering customers, Northrop Aircraft of Hawthorne, California, connected a 603 multiplying punch to one of their tabulating machines. That allowed Northrop’s users to print the results of a calculation on paper instead of punching them on cards. With a slight further modification and the addition of a small box that stored numbers in banks of relays, the machine could use punched cards run through the tabulator to control the sequences carried out by the multiplier.17
Logically, the arrangement was no different from an ordinary punched card installation, except that a set of cables and control boxes replaced the person whose job had been to carry decks of cards from one machine to the next. One of the Northrop engineers recalled years later that they rigged up the arrangement because they were running a problem whose next step depended on the results of the previous step. What this meant was that the normal decks of cards that ran through a machine were reduced to ‘‘a batch of one [card], which was awkward.’’18 In other words, with cables connecting the machines, the installation became one that executed instructions sequentially and was programmable in a more flexible way than plugging cables.
IBM later marketed a version of this ensemble as the Card- Programmed Calculator (CPC).19 Perhaps several hundred in all were installed between 1948 and the mid 1950s—far fewer than the thousands of tabulators, punches, and other equipment installed in the traditional way. But even that was many times greater than the number of electronic computer installations worldwide until about 1954. For engineering-
20 Chapter 1
oriented companies like Northrop, the CPC filled a pressing need that could not wait for the problems associated with marketing stored- program computers to be resolved.20
The Aberdeen calculators and the 604 were transitional machines, between calculators, tabulators, and genuine computers like the UNIVAC. The CPC carried the punched-card approach too far to be of value to computer designers. By the time of its introduction, it was already clear that the design used by the UNIVAC, in which both the instructions and the data were stored in an internal memory device, was superior. The Card-Programmed Calculator’s combination of program cards, plugboards, and interconnecting cables was like the epicycles of a late iteration of Ptolemaic cosmology, while the Copernican system was already gaining acceptance.21 Customers needing to solve difficult engineering problems, however, accepted it. It cost less than the computers then being offered, and it was available. Other southern California aerospace firms besides Northrop carefully evaluated the Card-Programmed Calculator against vendors’ claims for electronic computers.22 Nearly all of them installed at least one CPC.
The Stored-Program Principle
No one who saw a UNIVAC failed to see how much it differed from existing calculators and punched card equipment. It used vacuum tubes—thousands of them. It stored data on tape, not cards. It was a large and expensive system, not a collection of different devices. The biggest difference was its internal design, not visible to the casual observer. The UNIVAC was a ‘‘stored program’’ computer, one of the first. More than anything else, that made it different from the machines it was designed to replace.
The origins of the notion of storing a computer’s programs internally are clouded in war-time secrecy. The notion arose as Eckert, Mauchly, and others were rushing to finish the ENIAC to assist the U.S. Army, which was engaged in a ground war in Europe and North Africa. It arose because the ENIAC’s creators recognized that while the ENIAC was probably going to work, it was going to be a difficult machine to operate.
Applying the modern term ‘‘to program’’ to a computer probably originated with the ENIAC team at the Moore School. More often, though, they used the phrase ‘‘set up’’ to describe configuring the ENIAC to solve different problems.23 Setting up the ENIAC meant
The Advent of Commercial Computing, 1945–1956 21
plugging and unplugging a maze of cables and setting arrays of switches. In effect, the machine had to be rebuilt for each new problem it was to solve. When completed in late 1945, the ENIAC operated much faster than any other machine before it. But while it could solve a complex mathematical problem in seconds, it might take days to set up the machine properly to do that.
It was in the midst of building this machine that its creators conceived of an alternative. It was too late to incorporate that insight into the ENIAC, but it did form the basis for a proposed follow-on machine called the ‘‘EDVAC’’ (Electronic Discrete Variable Computer). In a description written in September of 1945, Eckert and Mauchly stated the concept succinctly: ‘‘An important feature of this device was that operating instructions and function tables would be stored exactly in the same sort of memory device as that used for numbers.’’24 Six months later, Eckert and Mauchly left the Moore School, and work on the EDVAC was turned over to others (which was mainly why it took five more years to finish building it). The concept of storing both instruc- tions and data in a common storage unit would become basic features of the UNIVAC and nearly every computer that followed.25
The stored-program principle was a key to the UNIVAC’s success. It allowed Eckert and Mauchly, first of all, to build a computer that had much more general capabilities than the ENIAC, yet required fewer vacuum tubes. It led to the establishment of ‘‘programming’’ (later ‘‘software’’) as something both separate from and as important as hardware design. The basics of this design remained remarkably stable during the evolution of computing from 1945 to 1995. Only toward the end of this period do we encounter significant deviations from it, in the form of ‘‘massively parallel’’ processors or ‘‘non–von Neumann’’ architectures.
John von Neumann’s Role
Although Eckert and Mauchly had realized as early as 1944 that computers would need to store the program, the ‘‘First Draft of a Report on the EDVAC,’’ by John von Neumann, dated June 30, 1945, is often cited as the founding document of modern computing.26 From it, and a series of reports co-authored by von Neumann a few years later, comes the term ‘‘von Neumann Architecture’’ to describe such a design.27 According to Herman Goldstine, an army officer assigned to the ENIAC project, John von Neumann (1903–1957) learned of the ENIAC from a chance meeting with him in the summer of 1944 at the
22 Chapter 1
Aberdeen, Maryland, railroad station.28 Despite his involvement in many other projects, including the design of the atomic bomb, von Neumann was sufficiently intrigued by what was going on at the Moore School to have himself introduced to Eckert and Mauchly and brought onto the project.
Eckert and Mauchly were at that time busy thinking of ways to improve the process of setting up a computer faster.29 One possibility was to use perforated paper tape to feed instructions, as several relay machines of the 1940s did, but this was too slow for the high speeds of the ENIAC’s calculating circuits. So were the decks of cards used by the Card- Programmed Calculator. In Mauchly’s words, ‘‘calculations can be per- formed at high speed only if instructions are supplied at high speed.’’30
In the midst of the ENIAC’s construction in 1944, Eckert wrote a ‘‘Disclosure of a Magnetic Calculating Machine,’’ in which he described the use of ‘‘[d]iscs or drums which have at least their outer edge made of a magnetic alloy’’ on which numbers can be stored.31 Although it focused on ways of designing a machine that was ‘‘speedier, simpler as well as providing features of utility, ruggedness and ease or repair,’’ the disclosure did not articulate the design concepts that later would become known as the stored-program principle.32 Von Neumann’s 1945 Report on the EDVAC went farther—it described a machine in terms of its logical structure rather than its hardware construction. The memorandum that Eckert and Mauchly submitted in September 1945, stated the principle succinctly: they wrote that instructions and numer- ical data would be stored ‘‘in exactly the same sort of memory device.’’33
From the above sequence of reports and memorandums it appears that Eckert and Mauchly had conceived of something like a stored- program principle by 1944, but that it was von Neumann who clarified it and stated it in a form that gave it great force. Von Neumann’s international reputation as a mathematician also gave the idea more clout than it might have had coming solely from Eckert and Mauchly, neither of whom were well-known outside the Moore School. Although the term ‘‘von Neumann Architecture’’ is too entrenched to be supplanted, Eckert and Mauchly, who demonstrated such a deep under- standing of the nature of electronic computing from an engineering perspective, deserve equal credit.34
In the summer of 1946, the Moore School and the U.S. military cosponsored a course on the ‘‘Theory and Techniques for Design of Electronic Digital Computers.’’ The course was a recognition of the school’s inability to accommodate the numerous requests for informa-
The Advent of Commercial Computing, 1945–1956 23
tion following the public unveiling of the ENIAC.35 That series of course lectures and the mimeographed reports that appeared a year or two later firmly established the Moore School’s approach to computer design. Machines soon appeared that were based on that concept. An experimental computer at the University of Manchester, England, was running test programs by mid-1948. Maurice Wilkes, of Cambridge University, implemented the idea in his EDSAC, operational in the spring of 1949. Eckert and Mauchly completed the BINAC later that year.36 And of course the UNIVAC would also employ it. Others would continue to propose and build electronic computers of alternate designs, but after the summer of 1946, computing’s path, in theory at least, was clear.
The von Neumann Architecture and Its Significance
Before providing a description of the UNIVAC, it is worth a brief look at the essentials of the architecture that von Neumann described in his 1945 report, especially those aspects of it that have remained stable through the past half-century of computer design.
Aside from the internal storage of programs, a major characteristic of a von Neumann computer is that the units that process information are separate from those that store it. Typically there is only a single channel between these two units, through which all transfers of information must go (the so-called von Neumann Bottleneck, about which more later). This feature arose primarily for engineering reasons: it was easier to design storage cells that did not also have to perform arithmetic on their contents.
The main characteristic is that instructions and data are stored in the same memory device, from which any datum can be retrieved as quickly as any other. This concept arose from considering that the processing unit of a computer should not have to sit idle awaiting delivery of the next instruction. Besides that, the ratio of instructions to data usually varies for each problem, so it would not make sense to dedicate separate, expensive storage devices to each. This design implies that one may treat a coded instruction as a piece of data and perform an operation on it, thus changing it into another instruction, but that was not fully under- stood at first. To give a sense of how this was first implemented, the UNIVAC main store could hold up to 1,000 ‘‘words,’’ which could either be numbers (11 digits plus sign), characters (12 characters per word), or instructions (6 characters per instruction; 2 in each word).37
24 Chapter 1
Finally, the basic cycle of a von Neumann computer is to transfer an instruction from the store to the processor, decode that instruction, and execute it, using data retrieved from that same store or already present in the processor. Once the processor executed an instruction, it fetched, decoded, and executed another, from the very next position in memory unless directed elsewhere. Having a fast storage device meant that the processor could branch to another stream of instructions quickly when- ever it was necessary. Except when explicit branch instructions are encountered, the flow through the instructions stored in the memory was sequential and linear.38 This concept, of fetching and then execut- ing a linear stream of instructions, is the most lasting of all; even computer designs that purport to be non–von Neumann typically retain the fetch-decode-execute heartbeat of a single-processor machine.39 As Alan Perlis once remarked, ‘‘Sometimes I think the only universal in the computing field is the fetch-execute cycle.’’40 The UNIVAC could perform this sequence and add two numbers in about half a millisecond.
Since 1990, computer systems with parallel processing structures have become more common, and genuine alternatives to the fetch-execute cycle have been accepted in a few limited markets. Elsewhere the von Neumann architecture, though much modified, prevails. The emer- gence of practical parallel designs reveals, however, the unifying effect of the von Neumann model as it influenced the computer design of the past five decades.
From ENIAC to UNIVAC: First Transformation 41
The UNIVAC was going to cut through the Gordian knot of solving complex problems with punched card equipment or plugboard control, and its designers knew that. The ENIAC, though ill-suited for many problems, nevertheless was in such demand that its physical transfer from Philadelphia to Aberdeen had to be put off. With the end of the War there was less urgency to compute firing tables, although the Aberdeen Proving Ground still expected the machine to be moved there for that purpose. After the public unveiling, a flood of interested parties was petitioning to use it. Mauchly reported, for example, that in March of 1948 Pratt & Whitney asked him if they could run an urgent problem ‘‘the week of April 17.’’ That gave him a ‘‘chuckle’’—by 1948 the ENIAC was already fully booked for the next two years!42
The Advent of Commercial Computing, 1945–1956 25
What was less well known was that the Moore School team had carefully evaluated the architecture of the follow-on computer, the EDVAC, in light of the problems it might be expected to solve. Von Neumann found that although it was initially intended for evaluating mathematical expressions, the EDVAC’s stored-program design made it ‘‘very nearly an ‘all-purpose machine’’’ and that it was better than punched card equipment for sorting data. This was a crucial observa- tion, as sorting was a central task for commercial work, and punched card equipment had been optimized for it.43
Still, the climate that surrounded the small group of engineers at the Eckert–Mauchly Computer Corporation was anything but favorable. Many experts were skeptical. Wallace Eckert still felt that modifications to punched card machines, not a radically new and expensive design, would better serve computing’s needs. Howard Aiken could not imagine that ‘‘the basic logics of a machine designed for the numerical solution of differential equations [could] coincide with the logics of a machine intended to make bills for a department store.’’44 Eckert and Mauchly knew otherwise. The UNIVAC’s logical structure meant that it could do those things and more. That knowledge drove them and their company through the late 1940s to enter the commercial area, with what eventually became the UNIVAC.
Their drive was matched by an equal, but opposite drive by the University of Pennsylvania to banish commercial interests from the academy. Administrators at Penn did not have the vision of a research university to support technology, which led eventually to the develop- ment of areas like Silicon Valley in California and Route 128 in Massachusetts. Irwin Travis, an administrator at the Moore School, asked that members of the staff sign a release form that would prevent them from receiving patent royalties on their inventions. He brooked no discussion. Eckert and Mauchly refused to sign. They resigned on March 31, 1946.45 The Philadelphia-Princeton region, once a contender for the title of center for computing technology, never recovered.
Eckert and Mauchly could have found work at other universities, or at IBM, but they chose instead the risky course of founding their own company. They formed a partnership, the Electronic Control Company, in 1946; in December 1948 they incorporated as the Eckert–Mauchly Computer Corporation. Added to the engineering problems of design- ing and building a universal computer and its associated tape drives, memory units, and input-output equipment, was the bigger problem of raising capital. The National Bureau of Standards was encouraging at
26 Chapter 1
first; through it Eckert and Mauchly carried out serious discussions with the U.S. Census Bureau. (Census was not allowed to contract for a machine still in development, so the NBS had to be brought in as an intermediary.) The Census Bureau is not usually considered among the technologically astute, but just as it helped inaugurate modern data processing in 1890 by working with Herman Hollerith, Census also helped make electronic computing’s transition from the university to the private sector.
Still there were roadblocks. The NBS commissioned a study, which resulted in conservative and skeptical conclusions about electronic computing in general, and Eckert–Mauchly in particular. Another study conducted by the National Research Council in 1947 produced equally negative conclusions, mentioned at the beginning of this chap- ter. This latter study later became infamous as the source of the statement about how only a few computers would satisfy the world’s needs. The search for funds took the fledgling company everywhere: from the American Totalisator Company, who wanted a computer to calculate betting odds at race tracks, to Northrop Aircraft, who wanted an airborne control system for an unmanned, long-range bomber.
Their frantic search for capital makes for a depressing story. But it had a bright side: people wanted this new machine. And as the example of American Totalisator showed, there were many possible customers beyond the obvious ones of the large military or government agencies.
On January 12, 1948, John Mauchly wrote a memorandum to his staff at the Eckert–Mauchly Computer Corporation in which he listed a total of twenty-two industries, government agencies, or other institutions he had contacted. Optimistically he gauged the status of each as a potential customer for a UNIVAC.46 In the next few years the under-capitalized company would have a great deal of trouble selling UNIVACs. But in the long run, Mauchly was exactly right: each of those industries, and many more, would find compelling reasons to purchase or lease electronic digital computers, if not from Eckert–Mauchly then from someone else. Here are some of the contacts Mauchly listed in his memo:
Prudential. [Edmund C. Berkeley]....says that considering the number of persons at Prudential who have now expressed themselves in favor of obtaining electronic equipment, he believes there will be no difficulty in getting an order for one UNIVAC.
Oak Ridge . . . . it was almost 100 percent certain that their purchase order would be approved by Army.
The Advent of Commercial Computing, 1945–1956 27
Army Map Service....Army Map Service has taken an interest in UNIVAC equipment.
Bureau of Aeronautics . . . . we could possibly obtain a contract.
The Metropolitan Insurance Company has a large problem involving a total file of 18,000,000 policies with 2,000,000 changes per week. There are about twenty digits of information for each policy. It appears that this is a natural application for the UNIVAC . . . . it would be worthwhile to follow it up.
Presidency College, Calcutta. Professor Mahalanobis . . . was anxious to contract for a UNIVAC as soon as we were in a position to make definite terms.
Aircraft Companies. A number of aircraft companies are good prospects.... There is no doubt that such companies could use UNIVAC equipment. We have had brief contact with Hughes Aircraft, Glen L. Martin, United Aircraft, North American Aviation, and have been told that Grumman goes in for some rather fancy calculations.
The Information Age had dawned.
UNIVAC
I am pleased that history recognizes the first to invent something, but I am more concerned with the first person to make it work.
—Grace Hopper 47
On March 31, 1951, the Eckert–Mauchly Division of Remington Rand turned over the first UNIVAC to the U.S. Census Bureau. A formal dedication ceremony was held in June at the Division’s modest factory in at 3747 Ridge Avenue in Philadelphia. Thus began the era of commer- cial sales of large-scale stored-program computers in the United States.48 The event was, however, less of a milestone than it appeared. That first UNIVAC remained at the plant until late December 1952, when it was shipped to Washington. Eckert and Mauchly needed it there: As the only working model of a machine they hoped to sell in quantity, they wanted to show it to other potential customers.49 And after having gone through heroic efforts to complete and debug the machine, they were appre- hensive about dismantling it, moving it, and setting it up again. The first UNIVAC to leave the factory and be installed on a customer’s premises was serial #2, installed at the Pentagon for the U.S. Air Force in June 1952.50 By 1954 about twenty were built and sold, at prices on the order of a million dollars for a complete system.51 Table 1.1 lists UNIVAC installations from 1951 through 1954.
J. Presper Eckert and John Mauchly, with the help of about a dozen technical employees, designed and built the UNIVAC (figure 1.3). They
28 Chapter 1
Table 1.1
UNIVAC installations, 1951–1954

Date
Summer 1951 late 1952 late 1952 Fall 1953
Fall 1953 Fall 1953 1954 1954 1954 1954 1954 1954 1954 1954 1954 1954 1954 1954 1954
Customer
U.S. Census Bureau U.S. Air Force, the Pentagon U.S. Army Map Service U.S. AEC, New York, NY (at NYU) U.S. AEC, Livermore, CA David Taylor Model Basin, Carderock, MD Remington Rand, New York, NY General Electric, Louisville, KY Metropolitan Life, New York, NY Wright-Patterson AFB, Dayton, OH U.S. Steel, Pittsburgh, PA Du Pont, Wilmington, DE U.S. Steel, Gar y, IN Franklin Life Insurance, Springfield, OH Westinghouse, Pittsburgh, PA Pacific Mutual Life Insurance, Los Angeles, CA Sylvania Electric, New York, NY Consolidated Edison, New York, NY Consolidated Edison, New York, NY
 
Note: This list is compiled from a variety of sources and does not include one or two UNIVACs that were completed but remained with Remington Rand. In some cases the dates are approximate. Depending on how one interprets ‘‘installa- tion,’’ the order listed here may be slightly different. UNIVACs were last installed in late 1958 or early 1959.
designed a machine that used four binary digits (bits) to code each decimal digit. In its central processor, four general-purpose accumula- tors carried out arithmetic. A word was 45 bits long; each word could represent 11 decimal digits plus a sign, or two instructions. The UNIVAC’s clock ran at 2.25 MHz, and it could perform about 465 multiplications per second. That was about the same as the ENIAC’s multiplication speed; but the UNIVAC’s tape system and stored-program architecture made it a much faster machine overall. ‘‘Delay lines’’ stored 1,000 words as acoustic pulses in tubes of mercury, while magnetic tape units stored up to one million characters on reels of half-inch metal tape.
The UNIVAC was rugged and reliable. Vacuum tube failures, the bane of all early systems, were kept to a reasonably low rate to ensure that the machine would remain useful for practical, day-to-day work. Statistics gathered by one customer, Metropolitan Life Insurance Company,
The Advent of Commercial Computing, 1945–1956 29

Figure 1.3
Grace Murray Hopper and colleagues seated at a UNIVAC console, ca. 1960. Reels of UNIVAC tape are visible on both sides of the control panel. (Source: Smithsonian Institution photo #83-14878, gift of Grace Murray Hopper.)
showed the central processor was available 81 percent of the time, a very high figure compared to contemporary vacuum-tube machines.52 The Census Bureau said, ‘‘We never encountered an incorrect solution to a problem which we were sure resulted from an internal computer error.’’53 The machine’s design reflected Eckert’s philosophy of conser- vative loads on the vacuum tube circuits, plus enough redundancy, to ensure reliable operation. Its central processor contained over 5,000 tubes, installed in cabinets that were ranged in a 10-foot by 14-foot rectangle. Inside this rectangle were the mercury delay-line tanks.
Many design features that later became commonplace first appeared in the UNIVAC: among them were alphanumeric as well as numeric processing, an extensive use of extra bits for checking, magnetic tapes for bulk memory, and circuits called ‘‘buffers’’ that allowed high-speed transfers between the fast delay line and slow tape storage units.54
30 Chapter 1
The UNIVAC in Use
A number of UNIVAC customers were private corporations, not military or defense agencies. And of those defense agencies that purchased UNIVACs, many did so for inventory, logistics, and other applications that in many ways were similar to what business customers bought the machine for. In short, and in contrast to the IBM 701 (discussed next), the UNIVAC inaugurated the era of large computers for what is now called ‘‘data processing’’ applications.
For most customers, what was revolutionary about the UNIVAC was not so much its stored-program design or even its electronic processor. It was the use of tape in place of punched cards. To them, the ‘‘Automatic’’ nature of the machine lay in its ability to scan through a reel of tape, find the correct record or set of records, perform some process in it, and return the results again to tape. In a punched card installation, these tasks were performed by people who had to carry large decks of cards from one punched card machine to another. That made punched card processing labor-intensive. Published descriptions of the UNIVAC nearly always referred to it as a ‘‘tape’’ machine. For General Electric, ‘‘the speed of computing is perhaps of tertiary importance only.’’55 To the extent that its customers perceived the UNIVAC as an ‘‘electronic brain,’’ it was because it ‘‘knew’’ where to find the desired data on a tape, could wind or rewind a tape to that place, and could extract (or record) data automatically. Customers regarded the UNIVAC as an information processing system, not a calculator. As such, it replaced not only existing calculating machines, but also the people who tended them.
The Census Bureau, which had been pivotal in getting the fledgling computer company going, hoped to use the UNIVAC for tabulating the 1950 Census. By the time it received its machine in 1951, however, much of the work had already been put on punched card machines for processing. In fact, the Census Bureau had to step aside while the U.S. Air Force and the Atomic Energy Commission commandeered the first machine off the production line, UNIVAC 1, for problems deemed more urgent by the federal government.56
Nevertheless, UNIVAC 1 was used for the production of part of the Second Series Population Tables for the states of Alabama, Iowa, Louisiana, and Virginia. This involved classifying individuals into one of several hundred groups, further grouping them by geographic location, and preparing tables showing the number of persons in each
The Advent of Commercial Computing, 1945–1956 31
group for each local area. The data for this operation, initially punched onto eleven million cards (one for each person), was transferred to tape for processing by the UNIVAC.57 The machine was also used for tabulating another subset of population involving about five million households. Each problem took several months to complete.
UNIVAC 2, installed at the Pentagon for the Air Comptroller, was intended for use in Project SCOOP (Scientific Computation of Opti- mum Problems), which grew out of wartime concerns with getting war materials and men across the Atlantic. Following the War, the newly created Air Force was faced with a mathematically similar problem in maintaining and supplying air bases scattered across the globe. Project SCOOP played a key role in the discovery of Linear Programming, a cornerstone of modern applied mathematics.58
It was for SCOOP that the Air Force had helped fund construction of a computer called SEAC (Standards Eastern Automatic Computer), but that machine’s limited Input/Output facilities made it less than ideal for this problem. Soon after its installation, UNIVAC 2 was put to work on SCOOP around the clock.59 Although the UNIVAC was superior to the SEAC in many ways, it, too, suffered from a slow output mechanism, which hampered its use for SCOOP. The UNIVAC’s UNIPRINTER was based around a standard Remington Rand electric typewriter, and it printed at a rate commensurate with such a machine, about ten characters per second, which was too slow for the data processing applications the UNIVAC was being sold for. In 1954 Remington Rand addressed the problem by introducing the UNIVAC High Speed Printer, which printed a full 130-character line at one time.60
The UNIVAC installed in 1954 at Air Force’s Air Material Command at Wright-Patterson AFB in Ohio performed similar tasks. One of its first jobs was to calculate ‘‘the complete Fiscal 1956 Budget estimate for airborne equipment spare parts, involving approximately 500,000 items.’’61 The Air Force noted that the machine did the job in one day, replacing a battery of punched card equipment.
Some UNIVACs performed classified weapons work in the spirit of the one-of-a-kind computers that preceded them. UNIVAC 5, installed at the Lawrence Livermore Labs in April 1953, was one of those. But even that machine did at least one calculation that was not for the purpose of weapons designs. In November 1952, before it was shipped to California, Remington Rand used it to predict Eisenhower’s victory over Adlai Stevenson in the 1952 presidential election. Narrated on ‘‘live’’ televi- sion, the event inaugurated the intrusion of television into national
32 Chapter 1
politics, and of computers into the public’s consciousness. For a brief period, the word ‘‘UNIVAC’’ was synonymous with computer, as ‘‘Thermos’’ was for vacuum bottles. That ended when IBM took the lead in the business.62
A final example of the UNIVAC in use comes from the experience at General Electric’s Appliance Park, outside Louisville, Kentucky. This installation, in 1954, has become famous as the first of a stored-program electronic computer for a nongovernment customer (although the LEO, built for the J. Lyons Catering Company in London, predated it by three years).
Under the direction of Roddy F. Osborn at Louisville, and with the advice of the Chicago consulting firm Arthur Andersen & Co., General Electric purchased a UNIVAC for four specific tasks: payroll, material scheduling and inventory control, order service and billing, and general cost accounting.63 These were prosaic operations, but GE also hoped that the computer would be more than just a replacement for the punched-card equipment in use at the time. For General Electric, and by implication for American industries, the UNIVAC was the first step into an age of ‘‘automation,’’ a change as revolutionary for business as Frederick W. Taylor’s Scientific Management had been a half-century earlier.
The term ‘‘automation’’ was coined at the Ford Motor Company in 1947 and popularized by John Diebold in a 1952 book by that title.64 Diebold defined the word as the application of ‘‘feedback’’ mechanisms to business and industrial practice, with the computer as the principal tool. He spoke of the 1950s as a time when ‘‘the push-button age is already obsolete; the buttons now push themselves.’’65 Describing the GE installation, Roddy Osborn predicted that the UNIVAC would effect the same kind of changes on business as it had already begun to effect in science, engineering, and mathematics. ‘‘While scientists and engineers have been wide-awake in making progress with these remarkable tools, business, like Rip Van Winkle, has been asleep. GE’s installation of a UNIVAC may be Rip Van Business’s first ‘blink.’’’66
To people at General Electric, these accounts of ‘‘electronic brains’’ and ‘‘automation’’ were a double-edged sword. The Louisville plant was conceived of and built to be as modern and sophisticated as GE could make it; that was the motivation to locate it in Kentucky rather than Massachusetts or New York, where traditional methods (and labor unions) held sway. At the same time, GE needed to assure its stock- holders that it was not embarking on a wild scheme of purchasing exotic,
The Advent of Commercial Computing, 1945–1956 33
fragile, and expensive equipment just because ‘‘longhair’’ academics— with no concern for profits—wanted it to.
Thus, GE had to emphasize the four mundane jobs, already being done by punched card equipment, to justify the UNIVAC. Once these jobs became routine, other, more advanced jobs would be given to the machine. Although automating those four tasks could have been done with a smaller computer, GE chose a UNIVAC in anticipation of the day when more sophisticated work would be done. These tasks would involve long-range planning, market forecasting based on demographic data, revamping production processes to reduce inventories and shipping delays, and similar jobs requiring a more ambitious use of corporate information.67 The more advanced applications would not commence until after the existing computerization of ‘‘bread and butter’’ work reached a ‘‘break even point . . . enough to convince management that a computer system can pay for itself in terms of direct dollar savings (people off the payroll) without waiting for the ‘jam’ of more glamorous applications.’’68
Indeed, the analysis of the UNIVACs benefits was almost entirely cast in terms of its ability to replace salaried clerks and their overhead costs of office space, furnishings, and benefits. Yet at the end of Osborn’s essay for the Harvard Business Review, the editors appended a quotation from Theodore Callow’s The Sociology of Work, published that year. That quotation began:
The Utopia of automatic production is inherently plausible. Indeed, the situa- tion of the United States today, in which poverty has come to mean the absence of status symbols rather than hunger and physical misery, is awesomely favorable when measured against the budgetary experience of previous generations or the contemporary experience of most of the people living on the other continents.69
It would not be the last time that the computer would be seen as the machine that would bring on a digital Utopia.
On Friday, October 15, 1954, the GE UNIVAC first produced payroll checks for the Appliance Park employees.70 Punched-card machines had been doing that job for years, but for an electronic digital computer, which recorded data as invisible magnetic spots on reels of tape, it was a milestone. Payroll must be done right, and on time. GE had rehearsed the changeover thoroughly, and they had arranged with Remington Rand that if their machine broke down and threatened to make the checks late, they could bring their tapes to another UNIVAC customer and run the job there.71 Over the course of the next year they had to
34 Chapter 1
exercise this option at least once. There were several instances where the checks were printed at the last possible minute, and in the early months it was common to spend much more time doing the job with UNIVAC than had been spent with punched card equipment. No payrolls were late.
IBM’s Response
At the time of the UNIVAC’s announcement, IBM was not fully committed to electronic computation and was vigorously marketing its line of punched card calculators and tabulators. But after seeing the competitive threat, it responded with several machines: two were on a par with the UNIVAC; another was more modest.
In May 1952, IBM announced the 701, a stored-program computer in the same class as the UNIVAC. Although not an exact copy, its design closely followed that of the computer that John von Neumann was having built at the Institute for Advanced Study at Princeton. That meant it used a memory device that retrieved all the digits of a word at once, rather than the UNIVAC’s delay lines that retrieved bits one at a time. Beginning in January of that year, IBM had hired John von Neumann as a consultant; as with the Institute for Advanced Study computer itself, von Neumann was not involved with the detailed design of the 701. (IBM engineers Jerrier Haddad and Nat Rochester were in charge of the project.) The first unit was installed at IBM’s offices in New York in December, with the first shipment outside IBM to the nuclear weapons laboratory at Los Alamos in early 1953.72
IBM called the 701 an ‘‘electronic data processing machine,’’ a term (coined by James Birkenstock) that fit well with ‘‘Electric Accounting Machine,’’ which IBM was using to describe its new line of punched card equipment. IBM deliberately avoided the word ‘‘computer,’’ which it felt was closely identified with the UNIVAC and with exotic wartime projects that appeared to have little relevance to business.
For main storage, the 701 used IBM-designed 3-inch diameter vacuum tubes similar to those used in television sets. (They were called ‘‘Williams tubes’’ after their British inventor, F. C. Williams.) Although they were more reliable than those in other contemporary computers, their unreliability was a weak link in the system. One story tells of a 701 behaving erratically at its unveiling to the press despite having been checked out thoroughly before the ceremony. The photographers’ flash bulbs were ‘‘blinding’’ the Williams tubes, causing them to lose data.
The Advent of Commercial Computing, 1945–1956 35
Another account said that because the memory’s Mean Time Between Failure (MTBF) was only twenty minutes, data had to be constantly swapped to a drum to prevent loss.73
Each tube was designed to hold 1,024 bits. An array of 72 tubes could thus hold 2,048 36-bit words, and transfer a word at a time by reading one bit from each of 36 tubes.74 Plastic tape coated with magnetic oxide was used for bulk memory, with a drum for intermediate storage. The processor could perform about 2,000 multiplications/second, which was about four times faster than the UNIVAC.
Within IBM, the 701 had been known as the Defense Calculator, after its perceived market. According to an IBM executive, the name also helped ‘‘ease some of the internal opposition to it since it could be viewed as a special project (like the bomb sights, rifles, etc., IBM had built during World War II) that was not intended to threaten IBM’s main product line.’’75 True to that perception, nearly all of the 19 models installed were to U.S. Defense Department or military aerospace firms.76 Initial rental fees were $15,000 a month; IBM did not sell the machines outright. If we assume the 701 was a million-dollar machine like the UNIVAC, the rental price seems low; certainly IBM could not have recouped its costs in the few years that the machine was a viable product.
The 701 customers initially used the machine for problems, many still classified, involving weapons design, spacecraft trajectories, and crypta- nalysis, which exercised the central processor more heavily than its Input/Output facilities. Punched card equipment had been doing some of that work, but it had also been done with slide rules, mechanical calculators, analog computers, and the Card-Programmed Calculator. Eventually, however, customers applied the 701 to the same kinds of jobs the UNIVAC was doing: logistics for a military agency, financial reports, actuarial reports, payrolls (for North American Aviation), and even predicting the results of a presidential election for network television. (In 1956, the 701 correctly predicted Eisenhower’s reelection.)77
Unlike the UNIVAC, the 701’s central processor handled control of the slow input/output (I/O) facilities directly. All transfers of data had to pass through a single register in the machine’s processor, which led to slow operation for tasks requiring heavy use of I/O. However, the 701’s lightweight plastic tape could start and stop much faster than the UNIVAC’s metal tape and thus speed up those operations. The tape drive also employed an ingenious vacuum-column mechanism, invented by James Wiedenhammer, which allowed the tape to start and stop quickly without tearing.
36 Chapter 1
For scientific and engineering problems, the 701’s unbalanced I/O was not a serious hindrance. Computer designers—the few there were in 1953—regarded it as an inelegant design, but customers liked it. The nineteen installations were enough to prevent UNIVAC from completely taking over the market and to begin IBM’s transition to a company that designed and built large-scale electronic digital computers.78
The 701 became IBM’s response to UNIVAC in the marketplace, but that had not been IBM’s intention. Before starting on the 701, IBM had developed a research project on a machine similar to the UNIVAC, an experimental machine called the Tape Processing Machine, or TPM. Its design was completed by March 1950.79 The TPM was a radical depar- ture from IBM’s punched card machinery in two ways. It used magnetic tape (like the UNIVAC), and its variable length record replaced the rigid 80-character format imposed by the punched card. Like the UNIVAC, it worked with decimal digits, coding each digit in binary.
IBM chose to market a second large computer specifically to business customers based on the Tape Processing Machine. Model 702 was announced in September 1953 and delivered in 1955. In many ways it was similar to the 701, using most of the same electronic circuits as well as the Williams Tube storage. By the time of the first 702 installations, magnetic core memories were beginning to be used in commercial machines. And 701 customers were finding that their machine, like any powerful general-purpose computer, could be used for business applications as well. IBM received many orders for 702s, but chose to build and deliver only fourteen, with other orders filled by another machine IBM brought out a few years later.80
Engineering Research Associates
A third firm entered the field of making and selling large digital computers in the early 1950s: Engineering Research Associates, a Twin Cities firm that had its origins in U.S. Navy-sponsored code-breaking activities during World War II.81 The Navy gave this work the name ‘‘Communications Supplementary Activity—Washington’’ (CSAW), but it was usually called ‘‘Seesaw’’ after its acronym. It was centered in Washington, on the commandeered campus of a girls school. After the War, two members of this group, Howard Engstrom and William Norris, felt that the talent and skills the Navy had assembled for the war effort were too valuable to be scattered, and they explored ways of keeping the group together. They decided to found a private company, and with
The Advent of Commercial Computing, 1945–1956 37
financial assistance from John E. Parker, they were incorporated as Engineering Research Associates, Inc., in early 1946. Parker was able to provide space in a St. Paul building that during the war had produced wooden gliders (including those used for the Normandy invasion).
Thus, by one of the coincidences that periodically occur in this history, the empty glider factory gave the Twin Cities an entree into the world of advanced digital computing. The factory was cold and drafty, but ERA had little trouble finding and hiring capable engineers freshly minted from the region’s engineering schools. Among them was a 1951 graduate of the University of Minnesota, who went over to ‘‘the glider factory’’ because he heard there might be a job there. His name was Seymour R. Cray.82 We will encounter Cray and his boss, William Norris, several times in later chapters.
ERA was a private company but was also captive to the Navy, from which it had sprung. (The propriety of this arrangement would on occasion cause problems, but none serious.) The Navy assigned it a number of jobs, or ‘‘tasks,’’ that ERA carried out. Most of these were highly classified and related to the business of breaking codes. Task 13, assigned in August 1947, was for a general-purpose electronic computer. ERA completed the machine, code-named ‘‘Atlas,’’ and asked the Navy to clear them for an unclassified version they could sell on the open market. In December 1951 they announced it as Model ‘‘1101’’: ‘‘13’’ in binary notation.83
As might be expected from a company like ERA, the 1101 was intended for scientific or engineering customers, and its design reflected that. Before it could begin delivering systems, however, ERA found itself needing much more capital than its founders could provide, and like the Eckert–Mauchly Computer Corporation, was purchased by Remington Rand. By mid-1952 Remington Rand could offer not one but two well- designed and capable computer systems, one optimized for science and engineering, the other for commercial use. Installations of the 1103, its successor, began in the fall of 1953. Around twenty were built. As with the IBM 701, most went to military agencies or aerospace companies.
In 1954 the company delivered an 1103 to the National Advisory Committee for Aeronautics (NACA) that employed magnetic core in place of the Williams Tube memory. This was perhaps the first use of core in a commercial machine. The 1103 used binary arithmetic, a 36-bit word length, and operated on all the bits of a word at a time. Primary memory of 1,024 words was supplied by Williams tubes, with an ERA- designed drum, and four magnetic tape units for secondary storage.84
38 Chapter 1
Following NACA’s advice, ERA modified the machine’s instruction set to include an ‘‘interrupt’’ facility—another first in computer design. (Core and interrupts will be discussed in detail in the next chapter.) These enhancements were later marketed as standard features of the 1103-A model.85 Another aerospace customer, Convair, developed a CRT tube display for the 1103, which they called the Charactron. This 7-inch tube was capable of displaying a 6 6 6 array of characters, which also affected the course of computer history.86 Overall, the 1103 competed well with the IBM 701, although its I/O facilities were judged somewhat inferior.
The Drum Machines
In the late 1930s, in what may have been the first attempt to build an electronic digital computer, J. V. Atanasoff conceived of a memory device consisting of a rotating drum on which 1,600 capacitors were placed, arrayed in 32 rows.87 His work influenced the developments of the next decade, although those who followed him did not ultimately adopt his method. In the following years several people continued to work on the idea of rotating magnetic devices for data storage, for example, Perry O. Crawford, who described such a device in his master’s thesis at MIT.88
After the War, the drum emerged as a reliable, rugged, inexpensive, but slow memory device. Drawing on wartime research on magnetic recording in both the United States and Germany, designers rediscov- ered and perfected the drum, this time using magnetic rather than capacitive techniques.
The leader in this effort was Engineering Research Associates. Before they were assigned ‘‘Task 13,’’ they were asked to research available memory technologies. By 1947 they had made some significant advances in recording speeds and densities, using a drum on which they had glued oxide-coated paper (figure 1.4).89 Within two years ERA was building drums that ranged from 4.3 to 34 inches in diameter, with capacities of up to two million bits, or 65,000 30-bit words. Access time ranged from 8 to 64 milliseconds.90 ERA used drums in the 1101; they also advertised the technology for sale to others.
CRC 102A
One of the first to take advantage of magnetic drums was was Computer Research Corporation of Hawthorne, California. This company was
The Advent of Commercial Computing, 1945–1956 39
  
Figure 1.4
Advertisement for magnetic drum memory units, from ERA. (Source: Electronics Magazine [April 1953]: 397.)
40 Chapter 1
founded by former employees of Northrop Aircraft Company, the company that had built the Card-Programmed Calculator described above. In 1953 they began selling the CRC-102A, a production version of a computer called CADAC that had been built for the Air Force. It was a stored-program, general-purpose computer based on a drum memory. The 102A had a simple design, using binary arithmetic, but a decimal version (CRC 102D) was offered in 1954.91 In some of the published descriptions, engineers describe its design as based directly on logic states derived from statements of Boolean algebra. This so-called West Coast design was seen as distinct from the designs of Eckert and Mauchly, who thought in terms not of logic states, but of current pulses gated through various parts of a machine. As computer engineer- ing matured, elements of both design approaches merged, and the distinction eventually vanished.92
The 102A’s drum memory stored 1,024 42-bit words; average access time was 12.5 msec. A magnetic tape system stored an additional 100,000 words. The principal input and output device was the Flexowriter, a typewriter-like device that could store or read keystrokes on strips of paper tape. It operated at about the speeds of an ordinary electric typewriter, from which it was derived. In keeping with its aerospace roots, Computer Research Corporation also offered a converter to enter graphical or other analog data into the machine.93 It was also possible to connect an IBM card reader or punch to the computer. The computer’s operating speed was estimated at about eleven multiplica- tions per second.94 The 102A was a well-balanced computer and sold in modest numbers. In 1954 the National Cash Register Company purchased CRC, and the 102 formed the basis of NCR’s entry into the computer business.95
Computer Research’s experience was repeated with only minor varia- tions between 1950 and 1954. Typically, a small engineering company would design a computer around a drum memory. I/O would be handled by a standard Flexowriter, or by punched card machines leased from IBM. The company would then announce the new machine at one of the Joint Computer Conferences of the Institute of Radio Engineers/Association for Computing Machinery. They would then get a few orders or development funds from the Air Force or another military agency. Even though that would lead to some civilian orders and modest productions runs, the company would still lack the resources to gear up for greater volume or advanced follow-on designs. Finally, a
Computer CE 30-201
Circle Elecom 100 MINIAC MONROBOT
Word length
10 dec. 40 bits 30 bits 10 dec. 20 dec.
Memor y capacity Speed (words) (mult./sec.)
4000 118 1024 20 512 20 4096 73 100 2
Manufacturer
Consolidated Engineering Pasadena, CA Hogan Labs New York, NY
Electronic Computer Corp Brooklyn, NY Physical Research Labs Pasadena, CA
Monroe Calculating Machine Co Orange, NJ
The Advent of Commercial Computing, 1945–1956 41
large, established company would buy the struggling firm, which would then serve as the larger company’s entree into computing.
Many of these computers performed well and represented a good value for the money, but there was no getting around the inherent slowness of the drum memory. Their input/output facilities also presented a dilemma. The Flexowriter was cheap, but slow. Attaching punched card equipment meant that a significant portion of the profits would go directly to IBM, and not to the struggling new computer company.
As mentioned, National Cash Register bought CRC. Electronic Computer Corporation, founded by Samuel Lubkin of the original UNIVAC team, merged with Underwood Corporation, known for its typewriters. (Underwood left the computer business in 1957.) Consoli- dated Engineering of Pasadena, California, was absorbed by Burroughs in 1956. The principal legacy of the drum computers may have been their role as the vehicle by which many of the business machine companies entered the computer business.
Table 1.2 lists several other magnetic drum computers announced or available by mid-1952. For each of these systems, the basic cost was from
Table 1.2
Commercially available small computers, ca. mid-1952
  
Source: Data from U.S. Navy, Navy Mathematical Computing Advisory Panel, Symposium on Commercially Available General-Purpose Electronic Digital Computers of Moderate Price (Washington, DC, 14 May 1952).
42 Chapter 1
$65,000 to $85,000 for a basic system exclusive of added memory, installation, or auxiliary I/O equipment.
Later Drum Machines, 1953–1956
LGP-30
In the mid-1950s a second wave of better-engineered drum computers appeared, and these sold in much larger quantities. They provided a practical and serious alternative for many customers who had neither the need nor the resources to buy or lease a large electronic computer.
The Librascope/General Precision LGP-30, delivered in 1956, repre- sented a minimum design for a stored-program computer, at least until the minicomputer appeared ten years later. It was a binary machine, with a 30-bit word length and a repertoire of only sixteen instructions. Its drum held 4,096 words, with an average access time of around 2.3 msec. Input and output was through a Flexowriter.
The LGP-30 had only 113 vacuum tubes and 1,350 diodes (unlike the UNIVAC’s 5,400 tubes and 18,000 diodes), and looked like an oversized office desk. At $30,000 for a basic but complete system, it was also one of the cheapest early computers ever offered. About 400 were produced and sold.96 It was not the direct ancestor of the minicomputer, which revolutionized computing in the late 1960s, but many minicomputer pioneers knew of the LGP-30. Librascope offered a transistorized version in 1962, but soon abandoned the general-purpose field and turned to specialized guidance-and-control computers for aerospace and defense customers.
Bendix G-15
The G-15, designed by Harry Huskey and built by Bendix, was perhaps the only computer built in the United States to have been significantly influenced by the design ideas of Alan Turing rather than John von Neumann. Both advocated the stored-program principle, with a provi- sion for conditional branching of instructions based on previously calculated results. For von Neumann, however, the fundamental concept was of a steady linear stream of instructions that occasionally branched based on a conditional test. Turing, on the other hand, felt that there was no fundamental linear order to instructions; for him, every order represented a transfer of control of some sort.97
Turing’s concept (much simplified here) was more subtle than the linear model, and fit well with the nature of drum-based computers.
The Advent of Commercial Computing, 1945–1956 43
Turing’s model required that every instruction have with it the address where the next instruction was located, rather than assuming that the next instruction would be found in the very next address location. In a drum computer, it was not practical to have instructions arranged one right after the other, since that might require almost a full revolution of the drum before the next one appeared under the read head. Program- mers of drum computers often developed complicated ‘‘minimum latency coding’’ schemes to scatter instructions around the drum surface, to ensure that the next instruction would be close to the read head when it was needed. (Note that none of this was required if a memory that took the same amount of time to access each piece of data was used.)
Harry Huskey, who had worked with Turing in 1947 on the ACE project at the National Physical Laboratory in England, designed what became the G-15 while at Wayne State University in Detroit in 1953. First deliveries were in 1956, at a basic price of $45,000. It was regarded as difficult to program, but for those who could program it, it was very fast. Bendix sold more than four-hundred machines, but the G-15’s success was not sufficient to establish Bendix as a major player in the computer field.98 Control Data Corporation later took over Bendix’s computer business, and Bendix continued to supply only avionics and defense electronics systems.
IBM 650
Along with the Defense Calculator (a.k.a. IBM 701), IBM was working on a more modest electronic computer. This machine had its origins in proposals for extensions of punched card equipment, which IBM had been developing at its Endicott, New York, plant. IBM’s internal manage- ment was hesitant about this project, nor was there agreement as to what kind of machine it would be. One proposal, dubbed ‘‘Wooden Wheel,’’ was for a plug-programmed machine like the 604 Multiplier.99 In the course of its development, the design shifted to a general-purpose, stored-program computer that used a magnetic drum for primary memory. (IBM’s acquisition, in 1949, of drum-memory technology from Engineering Research Associates was a key element in this shift.100) The machine, called the 650, was delivered in 1954 and proved very successful, with eventually around a thousand installations at a rental of around $3,500 a month.101
By the time of its announcement, the 650 had to compete with many other inexpensive drum machines. It outsold them all, in part because of
44 Chapter 1
IBM’s reputation and large customer base of punched card users, and in part because the 650 was perceived as easier to program and more reliable than its competitors. IBM salesmen were also quick to point out that the 650’s drum had a faster access time (2.4 msec) than other drum machines (except the Bendix G-15).102
The 650 was positioned as a business machine and continued IBM’s policy of offering two distinct lines of products for business and scientific customers. Ironically, it had less impact among business customers, for whom it was intended, than it had at universities. Thomas Watson Jr. directed that IBM allow universities to acquire a 650 at up to a 60 percent discount, if the university agreed to offer courses in business data processing or scientific computing. Many universities took up this offer, making the 650 the first machine available to nascent ‘‘computer science’’ departments in the late 1950s.103
Summar y
Very few of these machines of anybody’s manufacture were sold during the period we are talking about. Most of them, and I would guess 80 percent at least, were bought by the customer who made the buy, not the salesman who made the sale, although the salesman might get the commission.104
— Lancelot Armstrong
The ‘‘first generation’’ began with the introduction of commercial computers manufactured and sold in modest quantities. This phase began around 1950 and lasted through the decade. Computers of this era stored their programs internally and used vacuum tubes as their switching technology, but beyond that there were few other things they had in common. The internal design of the processors varied widely. Whether to code each decimal digit in binary or operate entirely in the binary system internally remained an unsettled question. The greatest variation was found in the devices used for memory: delay line, Williams tube, or drum. Because in one way or another all these techniques were unsatisfactory, a variety of machines that favored one design approach over another were built.
The Institute for Advanced Study’s reports, written by Arthur Burks, Herman Goldstine, and John von Neumann, emphasized the advantages of a pure binary design, with a parallel memory that could read and write all the bits of a word at once, using a storage device designed at RCA called the Selectron. By the time RCA was able to produce
The Advent of Commercial Computing, 1945–1956 45
sufficient quantities of Selectrons, however, core memory was being introduced, and the Selectron no longer looked so attractive. Only the Johnniac, built at the RAND Corporation, used it. Most of the other parallel-word computers used Williams Tubes.105 In practice, these tubes were plagued by reliability problems.106
The result was that memory devices that accessed bits one at a time, serially, were used in most first-generation computers. The fastest computers used mercury delay lines, but the most popular device was the rotating magnetic drum. A drum is fundamentally an electromecha- nical device and by nature slow, but its reliability and low cost made it the technology of choice for small-scale machines.
Commercial computing got off to a shaky start in the early 1950s. Eckert and Mauchly, who had a clear vision of its potential, had to sell their business to Remington Rand to survive, as did Engineering Research Associates. Remington Rand, however, did not fully under- stand what it had bought. IBM knew that computers were something to be involved with, but it was not sure how these expensive and complex machines might fit into its successful line of tabulating equipment. Customers took the initiative and sought out suppliers, perhaps after attending the Moore School session in 1946 or visiting a university where a von Neumann type machine was being built. These customers, from a variety of backgrounds, clamored for computers, in spite of a reluctance among UNIVAC or IBM salesmen to sell them.
The UNIVAC and the IBM 701 inaugurated the era of commercial stored-program computing. Each had its drawbacks, but overall they met the expectations of the customers who ordered them. The UNIVAC’s memory was reliable but slow; the 701’s was less reliable but faster. Each machine worked well enough to establish the viability of large compu- ters. Drum technology was providing storage at a lower cost per bit, but its speed was two orders of magnitude slower, closer to the speeds of the Card-Programmed Calculator (which was capable of reading 125 instruc- tion cards per minute), which had been available since the late 1940s from IBM. Given the speed penalty, drum-based computers would never be able to compete with the others, regardless of price. The many benefits promised in the 1940s by the stored-program electronic compu- ter architecture required high-capacity, high-speed memory to match electronic processing. With the advent of ferrite cores—and techniques for manufacturing them in large quantities—the memory problem that characterized the first generation was effectively solved.


SINCE THE appearance of the second edition in 2004, computing has continued to evolve rapidly. Most obviously, the Internet has grown to maturity such that it is now an integral part of most people’s lives in the developed world. Although com- puting was widely diffused by the end of the twentieth century, it has become truly ubiquitous only in the present century—a transition brought about by Internet commerce, consumer computing in the form of smartphones and tablet computers, and social networking.
The study of the history of computing has also matured as an academic enter- prise. When the first edition of this book appeared in 1996, the history of comput- ing had only recently begun to attract the attention of the academy, and research on this topic tended to be quite technically oriented. Since that time many new scholars with different perspectives have joined the field, and it is rare to find a sci- ence, technology, or business history conference that does not discuss develop- ments in, and impacts of, computing technology. In short, the user experience and business applications of computing have become central to much of the historical discourse. To harness these new perspectives in our narrative we have been joined by two additional authors, Nathan Ensmenger and Jeffrey Yost—both scholars from the rising generation.
As always in a new edition, we have sparingly revised the text to reflect changing perspectives and updated the bibliography to incorporate the growing literature of the history of computing. We have also introduced some substantial new material. In Chapter 3, which focuses on the precomputer era, we have added a section on Alan Turing. The year 2012 saw the centenary of the birth of Turing, whom many consider both a gay icon and the true inventor of the computer. Turing was indeed a key influence in the development of theoretical computer science, but we believe his influence on the invention of the computer has been overstated and have tried to give a measured assessment. In Chapter 6, on the maturing of the mainframe computer, we have condensed material on the computer industry in order to make space for a discussion of the diffusion of computing in government and business or- ganizations and the development of the computer professions. In Chapter 7, on real-time computing, we have taken advantage of a new strand of literature to dis- cuss the development of online consumer banking. In Chapters 8, 9, 10, and 11 we
ix
x Preface to the Third Edition
have made substantial additions to exploit the growing literature on the software professions, the semiconductor industry, pre-Internet networking, and the manu- facture of computers.
Unsurprisingly, Chapter 12, on the development of the Internet, is the most changed. The chapter has been extended and divided into two parts: the creation of the Internet, and the World Wide Web and its consequences. The latter part in- cludes new material on e-commerce, mobile and consumer computing, social net- working, and the politics of the Internet. It is extraordinary to think that when we were writing the first edition of this book in the early 1990s, the web had only just been conceived and its current ubiquity was beyond our imagining.
With these changes we hope that, for the next several years, the third edition of Computer will continue to serve as an authoritative, semi-popular history of computing.
INTRODUCTION
IN JANUARY 1983, Time magazine selected the personal computer as its Man of the Year, and public fascination with the computer has continued to grow ever since. That year was not, however, the beginning of the computer age. Nor was it even the first time that Time had featured a computer on its cover. Thirty-three years earlier, in January 1950, the cover had sported an anthropomorphized image of a computer wearing a navy captain’s hat to draw readers’ attention to the feature story, about a calculator built at Harvard University for the US Navy. Sixty years before that, in August 1890, another popular American magazine, Scientific Ameri- can, devoted its cover to a montage of the equipment constituting the new punched-card tabulating system for processing the US Census. As these magazine covers indicate, the computer has a long and rich history, and we aim to tell it in this book.
In the 1970s, when scholars began to investigate the history of computing, they were attracted to the large one-of-a-kind computers built a quarter-century earlier, sometimes now referred to as the “dinosaurs.” These were the first ma- chines to resemble in any way what we now recognize as computers: they were the first calculating systems to be readily programmed and the first to work with the lightning speed of electronics. Most of them were devoted to scientific and military applications, which meant that they were bred for their sheer number- crunching power. Searching for the prehistory of these machines, historians mapped out a line of desktop calculating machines originating in models built by the philosophers Blaise Pascal and Gottfried Leibniz in the seventeenth century and culminating in the formation of a desk calculator industry in the late nine- teenth century. According to these histories, the desk calculators were followed in the period between the world wars by analog computers and electromechanical calculators for special scientific and engineering applications; the drive to im- prove the speed of calculating machines during World War II led directly to the modern computer.
Although correct in the main, this account is not complete. Today, research sci- entists and atomic weapons designers still use computers extensively, but the vast majority of computers in organizations are employed for other purposes, such as word processing and keeping business records. How did this come to pass? To
xi
xii Introduction
answer that question, we must take a broader view of the history of the computer as the history of the information machine.
This history begins in the early nineteenth century. Because of the increasing population and urbanization in the West resulting from the Industrial Revolution, the scale of business and government expanded, and with it grew the scale of infor- mation collection, processing, and communication needs. Governments began to have trouble enumerating their populations, telegraph companies could not keep pace with their message traffic, and insurance agencies had trouble processing poli- cies for the masses of workers.
Novel and effective systems were developed for handling this increase in infor- mation. For example, the Prudential Assurance Company of England developed a highly effective system for processing insurance policies on an industrial scale using special-purpose buildings, rationalization of process, and division of labor. But by the last quarter of the century, large organizations had turned increasingly to tech- nology as the solution to their information-processing needs. On the heels of the first large American corporations came a business-machine industry to supply them with typewriters, filing systems, and duplication and accounting equipment.
The desk calculator industry was part of this business-machine movement. For the previous two hundred years, desk calculators had merely been handmade cu- riosities for the wealthy. But by the end of the nineteenth century, these machines were being mass-produced and installed as standard office equipment, first in large corporations and later in progressively smaller offices and retail establishments. Similarly, the punched-card tabulating system developed to enable the US govern- ment to cope with its 1890 census data gained wide commercial use in the first half of the twentieth century, and was in fact the origin of IBM.
Also beginning in the nineteenth century and reaching maturity in the 1920s and 1930s was a separate tradition of analog computing. Engineers built simplified physical models of their problems and measured the values they needed to calcu- late. Analog computers were used extensively and effectively in the design of elec- tric power networks, dams, and aircraft.
Although the calculating technologies available through the 1930s served busi- ness and scientific users well, during World War II they were not up to the de- mands of the military, which wanted to break codes, prepare firing tables for new guns, and design atomic weapons. The old technologies had three shortcomings: they were too slow in doing their calculations, they required human intervention in the course of a computation, and many of the most advanced calculating systems were special-purpose rather than general-purpose devices.
Because of the exigencies of the war, the military was willing to pay whatever it would take to develop the kinds of calculating machines it needed. Millions of dol- lars were spent, resulting in the production of the first electronic, stored-program
computers—although, ironically, none of them was completed in time for war work. The military and scientific research value of these computers was nevertheless appreciated, and by the time of the Korean War a small number had been built and placed in operation in military facilities, atomic energy laboratories, aerospace man- ufacturers, and research universities.
Although the computer had been developed for number crunching, several groups recognized its potential as a data-processing and accounting machine. The developers of the most important wartime computer, the ENIAC, left their univer- sity posts to start a business building computers for the scientific and business mar- kets. Other electrical manufacturers and business-machine companies, including IBM, also turned to this enterprise. The computer makers found a ready market in government agencies, insurance companies, and large manufacturers.
The basic functional specifications of the computer were set out in a report writ- ten by John von Neumann in 1945, and these specifications are still largely fol- lowed today. However, decades of continuous innovation have followed the original conception. These innovations are of two types. One is the improvement in components, leading to faster processing speed, greater information-storage ca- pacity, improved price/performance, better reliability, less required maintenance, and the like: today’s computers are literally millions of times better than the first computers on almost all measures of this kind. These innovations were made pre- dominantly by the firms that manufactured computers.
The second type of innovation was in the mode of operation, but here the agent for change was most often the academic sector, backed by government financing. In most cases, these innovations became a standard part of computing only through their refinement and incorporation into standard products by the computer manu- facturers. There are five notable examples of this kind of innovation: high-level pro- gramming languages, real-time computing, time-sharing, networking, and graphically oriented human-computer interfaces.
While the basic structure of the computer remained unchanged, these new components and modes of operation revolutionized our human experiences with computers. Elements that we take for granted today—such as having a computer on our own desk, equipped with a mouse, monitor, and disk drive—were not even conceivable until the 1970s. At that time, most computers cost hundreds of thousands, or even millions, of dollars and filled a large room. Users would sel- dom touch or even see the computer itself. Instead, they would bring a stack of punched cards representing their program to an authorized computer operator and return hours or days later to pick up a printout of their results. As the main- frame became more refined, the punched cards were replaced by remote termi- nals, and response time from the computer became almost immediate—but still only the privileged few had access to the computer. All of this changed with the
Introduction xiii
xiv Introduction
development of the personal computer and the growth of the Internet. The mainframe has not died out, as many have predicted, but computing is now available to the masses.
As computer technology became increasingly less expensive and more portable, new and previously unanticipated uses for computers were discovered—or in- vented. Today, for example, the digital devices that many of us carry in our brief- cases, backpacks, purses, or pockets serve simultaneously as portable computers, communications tools, entertainment platforms, digital cameras, monitoring de- vices, and conduits to increasingly omnipresent social networks. The history of the computer has become inextricably intertwined with the history of communications and mass media, as our discussion of the personal computer and the Internet clearly illustrates. But it is important to keep in mind that even in cutting-edge companies like Facebook and Google, multiple forms and meaning of the computer continue to coexist, from the massive mainframes and server farms that store and analyze data to the personal computers used by programmers to develop software to the mobile devices and applications with which users create and consume content. As the computer itself continues to evolve and acquire new meanings, so does our un- derstanding of its relevant history. But it is important to remember that these new understandings do not refute or supersede these earlier histories but rather extend, deepen, and make them even more relevant.
WE HAVE ORGANIZED the book in four parts. The first covers the way com- puting was handled before the arrival of electronic computers. The next two parts describe the mainframe computer era, roughly from 1945 to 1980, with one part devoted to the computer’s creation and the other to its evolution. The final part discusses the origins of personal computing and the Internet.
Part One, on the early history of computing, includes three chapters. Chapter 1 discusses manual information processing and early technologies. People often sup- pose that information processing is a twentieth-century phenomenon; this is not so, and the first chapter shows that sophisticated information processing could be done with or without machines—slower in the latter case, but equally well. Chap- ter 2 describes the origins of office machinery and the business-machine industry. To understand the post–World War II computer industry, we need to realize that its leading firms—including IBM—were established as business-machine manufac- turers in the last decades of the nineteenth century and were major innovators be- tween the two world wars. Chapter 3 describes Charles Babbage’s failed attempt to build a calculating engine in the 1830s and its realization by Harvard University and IBM a century later. We also briefly discuss the theoretical developments asso- ciated with Alan Turing.
Part Two of the book describes the development of the electronic computer, from its invention during World War II up to the establishment of IBM as the
dominant mainframe computer manufacturer in the mid-1960s. Chapter 4 covers the development of the ENIAC at the University of Pennsylvania during the war and its successor, the EDVAC, which was the blueprint for almost all subsequent computers up to the present day. Chapter 5 describes the early development of the computer industry, which transformed the computer from a scientific instrument for mathematical computation into a machine for business data processing. In Chapter 6 we examine the development of the mainframe computer industry, fo- cusing on the IBM System/360 range of computers, which created the first stable industry standard and established IBM’s dominance.
Part Three presents a selective history of some key computer innovations in the quarter-century between the invention of the computer at the end of the war and the development of the first personal computers. Chapter 7 is a study of one of the key technologies of computing, real time. We examine this subject in the context of commonly experienced applications, such as airline reservations, banking and ATMs, and supermarket bar codes. Chapter 8 describes the development of soft- ware technology, the professionalization of programming, and the emergence of a software industry. Chapter 9 covers the development of some of the key features of the computing environment at the end of the 1960s: time-sharing, minicomputers, and microelectronics. The purpose of the chapter is, in part, to redress the com- monly held notion that the computer transformed from the mainframe to the per- sonal computer in one giant leap.
Part Four gives a history of the developments of the last forty years that brought the computer to most people’s desktops and into their personal lives. Chapter 10 describes the development of the microcomputer from the first hobby computers in the mid-1970s up to its transformation into the familiar personal computer by the end of the decade. Chapter 11’s focus is on the personal-computer environment of the 1980s, when the key innovations were user-friendliness and the delivery of “content,” by means of CD-ROM storage and consumer networks. This decade was characterized by the extraordinary rise of Microsoft and the other personal- computer software companies. The book concludes with a discussion of the Inter- net. The focus is on the World Wide Web, its precedents in the information sciences, and its ever-evolving commercial and social applications.
We have included notes at the end of the book. These indicate the exact sources of our quotations and lead the interested reader to some of the major literature on the history of computing.
Introduction xv

Part One BEFORE THE COMPUTER

1 WHEN COMPUTERS WERE PEOPLE
THE WORD computer is a misleading name for the ubiquitous machine that sits on our desks. If we go back to the Victorian period, or even to the World War II era, the word meant an occupation, defined in the Oxford English Dictionary as “one who computes; a calculator, reckoner; specifically a person employed to make calculations in an observatory, in surveying, etc.”
In fact, although the modern computer can work with numbers, its main use is for storing and manipulating information—that is, for doing the kinds of jobs per- formed by a clerk, defined in the Oxford English Dictionary as “one employed in a subordinate position in a public or private office, shop, warehouse, etc., to make written entries, keep accounts, make fair copies of documents, do the mechanical work of correspondence and similar ‘clerkly’ work.”
The electronic computer can be said to combine the roles of the human com- puter and the human clerk.
LOGARITHMS AND MATHEMATICAL TABLES
The first attempt to organize information processing on a large scale using human computers was for the production of mathematical tables, such as logarithmic and trigonometric tables. Logarithmic tables revolutionized mathematical computation in the sixteenth and seventeenth centuries by enabling time-consuming arithmetic operations, such as multiplication and division and the extraction of roots, to be performed using only the simple operations of addition and subtraction. Trigono- metric tables enabled a similar speeding up of calculations of angles and areas in connection with surveying and astronomy. However, logarithmic and trigonomet- ric tables were merely the best-known general-purpose tables. By the late eighteenth
3
4 WHEN COMPUTERS WERE PEOPLE
century, specialized tables were being produced for several different occupations: navigational tables for mariners, star tables for astronomers, life insurance tables for actuaries, civil engineering tables for architects, and so on. All these tables were produced by human computers, without any mechanical aid.
For a maritime nation such as Great Britain, and later the United States, the timely production of reliable navigation tables free of error was of major economic importance. In 1766 the British government sanctioned the astronomer royal, Nevil Maskelyne, to produce each year a set of navigational tables to be known as the Nautical Almanac. This was the first permanent table-making project to be es- tablished in the world. Often known as the Seaman’s Bible, the Nautical Almanac dramatically improved navigational accuracy. It has been published without a break every year since 1766.
The Nautical Almanac was not computed directly by the Royal Observatory, but by a number of freelance human computers dotted around Great Britain. The calculations were performed twice, independently, by two computers and checked by a third “comparator.” Many of these human computers were retired clerks or clergymen with a facility for figures and a reputation for reliability who worked from home. We know almost nothing of these anonymous drudges. Probably the only one to escape oblivion was the Reverend Malachy Hitchins, an eighteenth- century Cornish clergyman who was a computer and comparator for the Nautical Almanac for a period of forty years. A lifetime of computational dedication earned him a place in the Dictionary of National Biography. When Maskelyne died in 1811—Hitchins had died two years previously—the Nautical Almanac “fell on evil days for about 20 years, and even became notorious for its errors.”
CHARLES BABBAGE AND TABLE MAKING
During this period Charles Babbage became interested in the problem of table making and the elimination of errors in tables. Born in 1791, the son of a wealthy London banker, Babbage spent his childhood in Totnes, Devon, a country town in the west of England. He experienced indifferent schooling but succeeded in teach- ing himself mathematics to a considerable level. He went to Trinity College, Cam- bridge University, in 1810, where he studied mathematics. Cambridge was the leading English university for mathematics, and Babbage was dismayed to discover that he already knew more than his tutors. Realizing that Cambridge (and En- gland) had become a mathematical backwater compared to continental Europe, Babbage and two fellow students organized the Analytical Society, which suc- ceeded in making major reforms of mathematics in Cambridge and eventually the whole of England. Even as a young man, Babbage was a talented propagandist.
Babbage left Cambridge in 1814, married, and settled in Regency London to lead the life of a gentleman philosopher. His researches were mainly mathematical,
and in 1816 his achievements were recognized by his election to the Royal Society, the leading scientific organization in Britain. He was then twenty-five—an enfant terrible with a growing scientific reputation.
In 1819 Babbage made the first of several visits to Paris, where he met a number of the leading members of the French Scientific Academy, such as the mathemati- cians Pierre-Simon Laplace and Joseph Fourier, with whom he formed lasting friendships. It was probably during this visit that Babbage learned of the great French table-making project organized by Baron Gaspard de Prony. This project would show Babbage a vision that would determine the future course of his life.
De Prony began the project in 1790, shortly after the French Revolution. The new government planned to reform many of France’s ancient institutions and, in particular, to establish a fair system of property taxation. To achieve this, up-to-date maps of France were needed. De Prony was charged with this task and was ap- pointed head of the Bureau du Cadastre, the French ordinance survey office. His task was made more complex by the fact that the government had simultaneously decided to reform the old imperial system of weights and measures by introducing the new rational metric system. This created within the bureau the job of making a complete new set of decimal tables, to be known as the tables du cadastre. It was by far the largest table-making project the world had ever known, and de Prony decided to organize it much as one would organize a factory.
De Prony took as his starting point the most famous economics text of his day, Adam Smith’s Wealth of Nations, published in 1776. It was Smith who first advo- cated the principle of division of labor, which he illustrated by means of a pin- making factory. In this famous example, Smith explained how the making of a pin could be divided into several distinct operations: cutting the short lengths of wire to make the pins, forming the pin head, sharpening the points, polishing the pins, packing them, and so on. If a worker specialized in a single operation, the output would be vastly greater than if a single worker performed all the operations that went into making a pin. De Prony “conceived all of a sudden the idea of applying the same method to the immense work with which I had been burdened, and to manufacture logarithms as one manufactures pins.”
De Prony organized his table-making “factory” into three sections. The first section consisted of half a dozen eminent mathematicians, including Adrien-Marie Legendre and Lazare Carnot, who decided on the mathematical formulas to be used in the calcu- lations. Beneath them was another small section—a kind of middle management— that, given the mathematical formulas to be used, organized the computations and compiled the results ready for printing. Finally, the third and largest section, which consisted of sixty to eighty human computers, did the actual computation. The com- puters used the “method of differences,” which required only the two basic operations of addition and subtraction, and not the more demanding operations of multiplica- tion and division. Hence the computers were not, and did not need to be, educated
Charles Babbage and Table Making 5
6 WHEN COMPUTERS WERE PEOPLE
beyond basic numeracy and literacy. In fact, most of them were hairdressers who had lost their jobs because “one of the most hated symbols of the ancient regime was the hairstyles of the aristocracy.”
Although the Bureau was producing mathematical tables, the operation was not itself mathematical. It was fundamentally the application of an organizational tech- nology, probably for the first time outside a manufacturing or military context, to the production of information. Its like would not be seen again for another forty years.
The whole project lasted about a decade, and by 1801 the tables existed in man- uscript form all ready for printing. Unfortunately, for the next several decades, France was wracked by one financial and political crisis after another, so that the large sum of money needed to print the tables was never found. Hence, when Bab- bage learned of the project in 1819, all there was to show of it was the manuscript tables in the library of the French Scientific Academy.
In 1820, back in England, Babbage gained some firsthand experience of table making while preparing a set of star tables for the Astronomical Society, a scientific society that he and a group of like-minded amateur scientists had established the same year. Babbage and his friend John Herschel were supervising the construction of the star tables, which were being computed in the manner of the Nautical Al- manac by freelance computers. Babbage’s and Herschel’s roles were to check the ac- curacy of the calculations and to supervise the compilation and printing of the results. Babbage complained about the difficulty of table making, finding it error- prone and tedious; and if he found it tedious just supervising the table making, so much the worse for those who did the actual computing.
Babbage’s unique role in nineteenth-century information processing was due to the fact that he was in equal measure a mathematician and an economist. The mathematician in him recognized the need for reliable tables and knew how to make them, but it was the economist in him that saw the significance of de Prony’s organizational technology and had the ability to carry the idea further.
De Prony had devised his table-making operation using the principles of mass production at a time when factory organization involved manual labor using very simple tools. But in the thirty years since de Prony’s project, best practice in facto- ries had itself moved on, and a new age of mass-production machinery was begin- ning to dawn. The laborers in Adam Smith’s pin-making factory would soon be replaced by a pin-making machine. Babbage decided that rather than emulate de Prony’s labor-intensive and expensive manual table-making organization, he would ride the wave of the emerging mass-production technology and invent a ma- chine for making tables.
Babbage called his machine a Difference Engine because it would use the same method of differences that de Prony and others used in table making. Babbage knew, however, that most errors in tables came not from calculating them but from
printing them, so he designed his engine to set the type ready for printing as well. Conceptually, the Difference Engine was very simple: it consisted of a set of adding mechanisms to do the calculations and a printing part.
Babbage applied his considerable skills as a publicist to promote the idea of the Difference Engine. He began his campaign by writing an open letter to the presi- dent of the Royal Society, Sir Humphrey Davy, in 1822, proposing that the gov- ernment finance him to build the engine. Babbage argued that high-quality tables were essential for a maritime and industrial nation, and that his Difference Engine would be far cheaper than the nearly one hundred overseers and human computers in de Prony’s table-making project. He had the letter printed at his own expense and ensured that it got into the hands of people of influence. As a result, in 1823 he obtained government funding of £1,500 to build the Difference Engine, with the understanding that more money would be provided if necessary.
Babbage managed to rally much of the scientific community to support his proj- ect. His boosters invariably argued that the merit of his Difference Engine was that it would eliminate the possibility of errors in tables “through the unerring certainty of mechanism.” It was also darkly hinted that the errors in the Nautical Almanac and other tables might “render the navigator liable to be led into difficulties, if not danger.” Babbage’s friend Herschel went a step further, writing: “An undetected er- ror in a logarithmic table is like a sunken rock at sea yet undiscovered, upon which it is impossible to say what wrecks may have taken place.” Gradually the danger of errors in tables grew into lurid tales that “navigational tables were full of errors which continually led to ships being wrecked.” Historians have found no evidence for this claim, although reliable tables certainly helped Britain’s maritime activity run smoothly.
Unfortunately, the engineering was more complicated than the conceptualiza- tion. Babbage completely underestimated the financial and technical resources he would need to build his engine. He was at the cutting edge of production technol- ogy, for although relatively crude machines such as steam engines and power looms were in widespread use, sophisticated devices such as pin-making machines were still a novelty. By the 1850s such machinery would be commonplace, and there would exist a mechanical-engineering infrastructure that made building them rela- tively easy. While building the Difference Engine in the 1820s was not in any sense impossible, Babbage was paying the price of being a first mover; it was rather like building the first computers in the mid-1940s: difficult and extremely expensive.
Babbage was now battling on two fronts: first, designing the Difference Engine and, second, developing the technology to build it. Although the Difference En- gine was conceptually simple, its design was mechanically complex. In the London Science Museum today, one can see evidence of this complexity in hundreds of Babbage’s machine drawings for the engines and in thousands of pages of his note- books. During the 1820s, Babbage scoured the factories of Europe seeking gadgets
Charles Babbage and Table Making 7
8 WHEN COMPUTERS WERE PEOPLE
and technology that he could use in the Difference Engine. Not many of his dis- coveries found their way into the Difference Engine, but he succeeded in turning himself into the most knowledgeable economist of manufacturing of his day. In 1832 he published his most important book, an economics classic titled Economy of Machinery and Manufactures, which ran to four editions and was translated into five languages. In the history of economics, Babbage is a seminal figure who con- nects Adam Smith’s Wealth of Nations to the Scientific Management movement, founded in America by Frederick Winslow Taylor in the 1880s.
The government continued to advance Babbage money during the 1820s and early 1830s, eventually totaling £17,000; and Babbage claimed to have spent much the same again from his own pocket. These would be very large sums in to- day’s money. By 1833, Babbage had produced a beautifully engineered prototype Difference Engine that was too small for real table making and lacked a printing unit, but showed beyond any question the feasibility of his concept. (It is still on permanent exhibit in the London Science Museum, and it works as perfectly to- day as it did then.)
To develop a full-scale machine Babbage needed even more money, which he requested in a letter in 1834 to the prime minister, the Duke of Wellington. Un- fortunately, at that time, Babbage had an idea of such stunning originality that he just could not keep quiet about it: a new kind of engine that would do all the Dif- ference Engine could do but much more—it would be capable of performing any calculation that a human could specify for it. This machine he called the Analyti- cal Engine. In almost all important respects, it had the same logical organization as the modern electronic computer. In his letter to the Duke of Wellington, Bab- bage hinted that instead of completing the Difference Engine he should be al- lowed to build the Analytical Engine. Raising the specter of the Analytical Engine was the most spectacular political misjudgment of Babbage’s career; it fatally un- dermined the government’s confidence in his project, and he never obtained an- other penny. In fact, by this time, Babbage was so thoroughly immersed in his calculating-engine project that he had completely lost sight of the original objec- tive: to make tables. The engines had become an end in themselves, as we shall see in Chapter 3.
CLEARING HOUSES AND TELEGRAPHS
While Babbage was struggling with his Difference Engine, the idea of large-scale information processing was highly unusual—whether it was organized manually or used machinery. The volume of activity in ordinary offices of the 1820s simply did not call for large clerical staffs. Nor was there any office machinery to be had; even adding machines were little more than a scientific novelty at this date, and the typewriter had yet to be invented. For example, the Equitable Society of London—
then the largest life insurance office in the world—was entirely managed by an of- fice staff of eight clerks, equipped with nothing more than quill pens and writing paper.
In the whole of England there was just one large-scale data-processing organiza- tion that had an organizational technology comparable with de Prony’s table- making project. This was the Bankers’ Clearing House in the City of London, and Babbage wrote the only contemporary published account of it.
The Bankers’ Clearing House was an organization that processed the rapidly in- creasing number of checks being used in commerce. When the use of checks became popular in the eighteenth century, a bank clerk physically had to take a check de- posited by a customer to the bank that issued it to have it exchanged for cash. As the use of checks gained in popularity in the middle of the eighteenth century, each of the London banks employed a “walk clerk,” whose function was to make a tour of all the other banks in the City, the financial district of London, exchanging checks for cash. In the 1770s, this arrangement was simplified by having all the clerks meet at the same time in the Five Bells Public House on Lombard Street. There they per- formed all the exchanging of checks and cash in one “clearing room.” This obviously saved a lot of walking time and avoided the danger of robbery. It also brought to light that if two banks had checks drawn on each other, the amount of cash needed for settlement was simply the difference between the two amounts owed, which was usually far less than the total amount of all the checks. As the volume of business ex- panded, the clearing room outgrew its premises and moved several times. Eventu- ally, in the early 1830s, the London banks jointly built a Bankers’ Clearing House at 10 Lombard Street, in the heart of London’s financial center.
The Bankers’ Clearing House was a secretive organization that shunned visitors and publicity. This was because the established banks wanted to exclude the many banks newly formed in the 1820s (which the Clearing House succeeded in doing until the 1850s). Babbage, however, was fascinated by the clearing house concept and pulled strings to gain entry. The secretary of the Bankers’ Clearing House was a remarkable man by the name of John Lubbock, who, besides being a leading fig- ure in the City, was also an influential amateur scientist and vice president of the Royal Society. Babbage wrote to Lubbock in October 1832 asking if it were “possi- ble that a stranger be permitted as a spectator.” Lubbock replied, “You can be taken to the clearing house . . . but we wish it not to be mentioned, so that the public may fancy they can have access to the sanctum sanctorum of banking, and we wish of course not to be named.” Babbage was captivated by Lubbock’s scientifically or- ganized system, which, despite Lubbock’s proscription, he described in glowing terms in the Economy of Manufactures:
In a large room in Lombard Street, about thirty clerks from the several London bankers take their stations, in alphabetical order, at desks placed round the room;
Clearing Houses and Telegraphs 9
10
WHEN COMPUTERS WERE PEOPLE
each having a small open box by his side, and the name of the firm to which he belongs in large characters on the wall above his head. From time to time other clerks from every house enter the room, and, passing along, drop into the box the checks due by that firm to the house from which this distributor is sent.
Most of the day was spent by clerks exchanging checks with one another and en- tering the details in ledgers. At four o’clock in the afternoon, the settlements be- tween the banks would begin. The clerk for each bank would total all the checks received from other banks for payment and all the checks presented for payment to other banks. The difference between these two numbers would then be either paid out or collected.
At five o’clock, the inspector of the clearing house took his seat on a rostrum in the center of the room. Then, the clerks from all the banks who owed money on that day paid the amount due in cash to the inspector. Next, the clerks of all the banks that were owed money collected their cash from the inspector. Assuming that no mistakes had been made (and an elaborate accounting system using preprinted forms ensured this did not happen very often), the inspector was left with a cash balance of exactly zero.
The amount of money flowing through the Bankers’ Clearing House was stag- gering. In the year 1839, £954 million was cleared—the equivalent of several hun- dred billion dollars in today’s money. On the busiest single day more than £6 million was cleared, and about half a million pounds in bank notes were used for the settlement. Eventually, the need for cash was eliminated altogether through an arrangement by which each bank and the Clearing House had an account with the Bank of England. Settlements were then made simply by transferring an amount from a bank’s account to that of the Clearing House, or vice versa.
Babbage clearly recognized the significance of the Bankers’ Clearing House as an example of the “division of mental labor,” comparable with de Prony’s table- making project and his own Difference Engine. He remained deeply interested in large-scale information processing all his life. For example, in 1837 he applied un- successfully to become registrar general and director of the English population cen- sus. But by the time really big information-processing organizations came along in the 1850s and 1860s—such as the great savings banks and industrial insurance companies—Babbage was an aging man who had ceased to have any influence.
The Bankers’ Clearing House was an early example of what would today be called financial infrastructure. The Victorian period was the great age of physical and financial infrastructure investment. Between 1840 and 1870, Britain’s invest- ment in rail track grew from 1,500 to over 13,000 miles. Alongside this physical and highly visible transport infrastructure grew a parallel, unseen information in- frastructure known as the Railway Clearing House, which was modeled very closely on the Bankers’ Clearing House. Established in 1842, the Railway Clearing House
rapidly became one of the largest data-processing bureaucracies in the world. By 1870 there were over 1,300 clerks processing nearly 5 million transactions a year.
Another vital part of the Victorian information infrastructure was the telegraph, which began to compete with the ordinary postal system in the 1860s. Telegrams were expensive—one shilling for a twenty-word message compared with as much as you could want to write in a letter for one penny—but very fast. A telegram would speed across the country in an instant and arrive at its final destination in as little as an hour, hand-delivered by a telegraph boy.
Rather like the Internet in our own time, the telegraph did not originate as a planned communications system. Instead it began as a solution to a communica- tions problem in the early rail system. There was a widely held fear among the public of a passenger train entering a section of track while another was heading in the opposite direction (in practice there were very few such accidents, but this did not diminish public concern). To solve the problem, inventive engineers strung up an electrical communication system alongside the track so that the signalmen at each end could communicate. Now a train could not enter a single-track section until two human operators agreed that it was safe to do so. Of course, it was not long before a commercial use was found for the new electrical signaling method. Newspapers and commercial organizations were willing to pay for news and mar- ket information ahead of their competitors. Suddenly, telegraph poles sprang up alongside railway tracks; some systems were owned by the railway companies, some by newly formed telegraph companies. Although messages were sent by elec- tricity, the telegraph still needed a large clerical labor force to operate the ma- chines that transmitted the messages. Much of the labor was female—the first time that female clerical labor had been used on any scale in Britain. The reason for this was that telegraph instruments were rather delicate and it was believed that women—especially seamstresses familiar with sewing machines—would have more dexterity than men.
By the mid-1860s there were over 75,000 miles of telegraph lines in Britain, op- erated by six main companies. However, each system operated independently and it was difficult for a telegram originating in one network to make use of another. In 1870, the British government stepped in to integrate the systems into a national telegraph network. Once this was done, telegraph usage simply exploded. More telegraph lines were erected and old ones were renewed. Telegraph offices were es- tablished in every significant town. Telegraph schools were set up in London and the provinces to train young men and women in Morse telegraphy. The cost of a telegram fell to sixpence for a dozen words.
The transmission of telegrams presented some interesting technical problems. Chief among these was the need to send telegrams between locations that were not directly connected by a telegraph line. Consider the problem of a cigar manufac- turer in Edinburgh, Scotland, negotiating with a tobacco importer in Bristol,
Clearing Houses and Telegraphs 11
12 WHEN COMPUTERS WERE PEOPLE
England, some 350 miles south. There was no direct connection between these two great cities. Instead the telegram had to be passed, rather like a baton in a relay race, through the telegraph offices of intermediate cities: Edinburgh to Newcastle, Newcastle to York, York to Manchester, Manchester to Birmingham, and finally Birmingham to Bristol. At each intervening telegraph office the message was re- ceived by a telegraphist on a Morse sounder and written out in longhand. The mes- sage would then be resent by another telegraphist to the next telegraph office in the chain. Although labor-intensive, the system was very resilient. If the telegraph lines between York and Manchester, say, were storm-damaged or simply very busy, the operator might send the message via Sheffield, which was not too much of a diver- sion. Sheffield would then send the message on its southerly route. Telegraphists needed to have a good knowledge of national geography.
After the government took over the telegraph system, and because London was the political and commercial center of Britain, it made sense for all major cities to have direct lines into the capital. In 1874 a central hub, the Central Telegraph Of- fice, was established with a direct connection to “every town of importance in the United Kingdom.” The Central Telegraph Office occupied a purpose-built struc- ture in St. Martin’s Le Grand, sited between Parliament, on the one hand, and the financial district and newspaper offices in Fleet Street, on the other. The office was the epitome of scientific modernity and featured in illustrated books and maga- zines. From the day it began operations, the great majority of national telegraph traffic passed through it: now our cigar manufacturer in Edinburgh could commu- nicate with his tobacco importer in Bristol with just a single hop. This was faster, cheaper, and less likely to introduce transcription errors in the message.
In 1874, the Illustrated London News produced a full-page engraving of a gallery in the Central Telegraph Office. The image shows an information factory frozen in time: row upon row of young men and women are operating telegraph instru- ments, supervisors (generally just a little older than their charges) organize the work from a massive sorting table at the front of the room, while messenger boys (mostly fresh out of elementary school) run up and down the rows of telegraph stations col- lecting messages as they are transcribed and distributing them for onward transmis- sion. The writer of the article explained—in words that spoke not only of the telegraph but of the times in which he lived:
It is a cheerful scene of orderly industry, and it is, of course, not the less pleasing because the majority of the persons here are young women, looking brisk and happy, not to say pretty, and certainly quite at home. Each has her own instru- ment on the desk before her. She is either just now actually busied in working off or in reading some message, or else, for the moment she awaits the signal, from a distant station, to announce a message for her reception. Boys move here and there about the galleries, with the forms of telegrams, which have been received
Herman Hollerith and the 1890 Census 13
in one part of the instrument-room, and which have to be signaled from another, but which have first to be conveyed, for record, to the nearest check-tables and sorting-tables in the centre.
The journalist—evidently a man with a taste for statistics—noted that there were 1,200 telegraphists, of whom 740 were female, and 270 boy messengers. Each day between 17,000 and 18,000 messages were transmitted between provincial telegraph offices, while nearly as many again were transmitted within London. But this was only the beginning. By the turn of the century, the Central Telegraph Of- fice employed no fewer than 4,500 clerks and transmitted between 120,000 and 165,000 telegrams a day. It was the largest office in the world.
HERMAN HOLLERITH AND THE 1890 CENSUS
Compared to Europe, the United States was a latecomer to large-scale data process- ing. That’s because it lagged twenty or thirty years behind Europe in its economic development. When Britain, Germany, and France were industrializing in the 1830s, the United States was still primarily an agricultural country. It was not until after the Civil War that US businesses began to develop big offices, but this delay enabled them to take full advantage of the newly emerging office technologies.
Before the Civil War the only American data-processing bureaucracy of major importance was the Bureau of the Census in Washington, DC. The population cen- sus was established by an act of Congress in 1790 to determine the “apportionment” of members of the House of Representatives. The first census in 1790 estimated the population of the United States at 3.9 million and consequently established that there should be an apportionment of one representative for each 33,000 people, or 105 representatives. The early census data processing was very small scale, and no records exist as to how it was organized. Even by 1840, when the population was 17.1 million, there were still only 28 clerks in the Bureau of the Census. Twenty years later, however, by the 1860 census, a major bureaucracy was in place that em- ployed 184 clerks to count a population of 31.4 million. For the 1870 census, there were 438 clerks, and the census reports amounted to 3,473 pages.
After that, the growth of the census was simply explosive. The census of 1880 probably represented a high point in manual data processing in the United States, when no fewer than 1,495 clerks were employed to process the census data. The data-processing method in use then was known as the “tally system.” This can best be understood by an example. One of the reports produced by the census was a table of the age structure of the population for each of the states, and the major cities and towns (that is, the number of males and females, in their ethnic cate- gories, of each age). A tally clerk was provided with a large tally sheet, ruled into a
14 WHEN COMPUTERS WERE PEOPLE
grid, with a dozen columns and many rows. Each pair of columns corresponded to males and females of a particular ethnic group. The rows corresponded to the age of an individual—under one year of age, one year of age, two years of age, and so on, up to a hundred years of age and over. The tally clerk would take a stack of cen- sus forms from an “enumeration district” (representing about a hundred families) and would proceed to examine the age, sex, and ethnic origin of each person on each form, putting a check mark in the appropriate cell of the grid. When the pile of forms had been processed in this way, the clerk would count the number of check marks in each of the cells and write the result at the side in red ink. This would be repeated for every enumeration district in the city. Finally, another clerk would total all the red-inked numbers on all the tally sheets for a city, entering the results onto a consolidation sheet, which would eventually become one of the ta- bles in the census report.
The work of the census clerks was tedious beyond belief, prompting a journalist of the period to write: “The only wonder . . . is, that many of the clerks who toiled at the irritating slips of tally paper in the census of 1880 did not go blind and crazy.” More than twenty-one thousand pages of census reports were produced for the 1880 census, which took some seven years to process. This unreasonably long time provided a strong motive to speed up the census by mechanization or any other means that could be devised.
One person who was acutely aware of the census problem was a remarkable young engineer by the name of Herman Hollerith (1859–1929). He later devel- oped a mechanical system for census data processing, commercialized his invention by establishing the Tabulating Machine Company in 1896, and laid the founda- tions of IBM. Along with Babbage, Hollerith is regarded as one of the seminal nineteenth-century figures in the development of information processing. Though Hollerith was not a deep thinker like the polymath Babbage, he was practical where Babbage was not. Hollerith also had a strong entrepreneurial flair, so that he was able to exploit his inventions and establish a major industry.
Hollerith grew up in New York and attended Columbia University, where one of his professors was an adviser to the Bureau of the Census in Washington. He in- vited the newly graduated Hollerith to become his assistant. While with the Census Bureau, Hollerith saw for himself the extraordinary scale of clerical activity—there was nothing else in the country to compare with it at the time. This familiarity with census operations enabled him to devise an electrical tabulating system that would mechanize much of the clerical drudgery.
Hollerith’s key idea was to record the census return for each individual as a pat- tern of holes on punched paper tape or a set of punched cards, similar to the way music was recorded on a string of punched cards on fairground organettes of the period. It would then be possible to use a machine to automatically count the holes and produce the tabulations. In later years Hollerith would reminisce on the
Herman Hollerith and the 1890 Census 15
origins of the idea: “I was traveling in the West and I had a ticket with what I think was called a punch photograph. [The conductor] punched out a description of the individual, as light hair, dark eyes, large nose, etc. So you see, I only made a punch photograph of each person.”
In 1888 the preparations for the 1890 census had begun under the direction of a newly appointed superintendent of the census, Robert P. Porter. Porter, an English-born naturalized American, was a charismatic individual. He was a diplo- mat, an economist, and a journalist; founder and editor of the New York Press; an industrial pundit; and a well-known exponent on statistics. As soon as he was ap- pointed superintendent, he set up a commission to select by competition an alter- native to the system of tally sheets used in the 1880 and previous censuses. He was already an enthusiast for Hollerith’s system; as a journalist he had written an article about it, and would later become chairman of the British Tabulating Machine Company (the ancestor of International Computers, which became Europe’s largest computer company). But to ensure a fair contest, he disallowed himself from being a judge of the competition.
Three inventors entered the competition, including Hollerith, and all of them proposed using cards or slips of paper in place of the old tally sheets. One of Hol- lerith’s rivals proposed transcribing the census return for each individual onto a slip of paper, using inks of different colors for the different questions, so that the data could be easily identified and rapidly counted and sorted by hand. The second competitor had much the same idea but used ordinary ink and cards of different colors, which would then be easy to identify and arrange by hand. These two sys- tems were entirely manual and were similar to the card-based record systems that were beginning to emerge ad hoc in big commercial offices. The great advantage of the Hollerith system over these others was that once the cards had been punched, all the sorting and counting would be handled mechanically.
In the fall of 1889, the three competitors were required to demonstrate their sys- tems by processing the 10,491 returns of the 1880 population census for the dis- trict of St. Louis. The trial involved both recording the returns on the cards or paper slips and tabulating them to produce the required statistical tables. So far as recording the data on cards was concerned, the Hollerith system proved little faster than the competing manual systems. But in the tabulation phase it came into its own, proving up to ten times as fast as the rival systems. Moreover, once the cards had been punched, the more tabulations that were required the more cost-effective the Hollerith system would prove. The commission was unanimous in recom- mending that the Hollerith Electric Tabulating System be adopted for the 1890 census.
As preparations for the eleventh United States population census got into high gear, Superintendent Porter “rounded up what appeared to be every square foot of empty office and loft space in downtown Washington.” At the same time, Hollerith
16 WHEN COMPUTERS WERE PEOPLE
made the transition from inventor to supervising manufacturer and subcontracted Western Electric to assemble his census machines. He also negotiated with paper manufacturers to supply the 60 million-plus manila cards that would be needed for the census.
On 1 June 1890, an army of forty-five thousand census enumerators swept the nation, preparing the schedules for the 13 million households and dispatching them to Washington. At the Census Bureau two thousand clerks were assembled in readiness, and on 1 July they began to process the greatest and most complete cen- sus the world had ever seen. It was a moment for the American people to “feel their nation’s muscle.”
On 16 August 1890, six weeks into the processing of the census, the grand total of 62,622,250 was announced. But this was not what the allegedly fastest-growing nation in the world wanted to hear:
The statement by Mr. Porter that the population of this great republic was only 62,622,250 sent into spasms of indignation a great many people who had made up their minds that the dignity of the republic could only be supported on a total of 75,000,000. Hence there was a howl, not of “deep-mouthed welcome,” but of frantic disappointment. And then the publication of the figures of New York! Rachel weeping for her lost children and refusing to be comforted was a mere puppet-show compared with some of our New York politicians over the strayed and stolen of Manhattan Island citizens.
The press loved the story. In an article headlined “Useless Machines,” the Boston Herald roasted Porter and Hollerith; “Slip Shod Work Has Spoiled the Census,” exclaimed the New York Herald; and the other papers soon took up the story. But Hollerith and Porter never had any real doubts about the system.
After the rough count was over and the initial flurry of public interest had sub- sided, the Census Bureau settled into a routine. Recording all the data onto the cards was a task that kept the seven hundred card punches in almost constant op- eration. A punching clerk—doing what was optimistically described as “vastly in- teresting” work—could punch an average of seven hundred cards in a six-and-a-half-hour day. Female labor was heavily used for the first time in the census, which a male journalist noted “augurs well for its conscientious perfor- mance” because “women show a moral sense of responsibility that is still beyond the average.” More than 62 million cards were punched, one for each citizen.
The cards then were processed by the census machines, each of which could do the work of twenty of the former tally clerks. Even so, the original fifty-six census machines eventually had to be increased to a hundred (and the extra rentals signifi- cantly added to Hollerith’s income). Each census machine consisted of two parts: a
Herman Hollerith and the 1890 Census 17
tabulating machine, which could count the holes in a batch of cards, and the sort- ing box, into which cards were placed by the operator ready for the next tabulating operation. A census machine operator processed the cards one by one, by reading the information using a “press” that consisted of a plate of 288 retractable spring- loaded pins. When the press was forced down on the card, a pin meeting the solid material was pushed back into the press and had no effect. But a pin encountering a hole passed straight through, dipped into a mercury cup, and completed an electri- cal circuit. This circuit would then be used to add unity to one of forty counters on the front of the census machine. The circuit could also cause the lid of one of the twenty-four compartments of the sorting box to fly open—into which the operator would place the card so that it would be ready for the next phase of the tabulation.
Thus, if one counter of the tabulating machine and one sorting box compart- ment were wired up for a male subject and another counter and compartment were wired up for a female subject, the census machine—by reading a batch of cards— could determine the number of males and females represented and then separate the cards accordingly. In practice, counts were much more complicated than this, in order to extract as much information as possible from the cards. Counts were de- signed to use all forty counters on the census machine and as many as possible of the twenty-four compartments in the sorting box.
At any one time there would be upward of eighty clerks operating the machines. Each operator processed at least a thousand cards an hour. In a typical day the com- bined operation would eat through nearly half a million cards: “In other words, the force was piercing its way through the mass at the rate of 500 feet daily, and han- dling a stack of cards nearly as high as the Washington Monument.” As each card was read, the census machine gave a ring of a bell to indicate that it had been cor- rectly sensed. The floor full of machines ringing away made a sound “for all the world like that of sleighing,” commented a journalist. It was an awe-inspiring sight and sound; and, as the same journalist noted, “the apparatus works as unerringly as the mills of the Gods, but beats them hollow as to speed.” Hollerith personally su- pervised the whole operation, combating both natural and unnatural mechanical breakdowns. One veteran of the census recounted:
Herman Hollerith used to visit the premises frequently. I remember him as very tall and dark. Mechanics were there frequently too, to get ailing machines back in operation and loafing employees back at work. The trouble was usually that somebody had extracted the mercury from one of the little cups with an eye- dropper and squirted it into a spittoon, just to get some unneeded rest.
The 1890 census was processed in two and a half years, compared with the seven years of the previous census. Altogether, the census reports totaled 26,408 pages.
18 WHEN COMPUTERS WERE PEOPLE
The total cost was $11.5 million, and estimates indicated that without the Hol- lerith system it would have cost $5 million more. For those with eyes to see, the Hollerith machines had opened up a whole new vista of mechanized information processing.
AMERICA’S LOVE AFFAIR WITH OFFICE MACHINERY
While the Hollerith system was the most visible use of mechanical information processing in the United States, it was really only one of many examples of what we now call “information technology” that developed in the twenty years following the Civil War. The Hollerith system was not in any sense typical of this informa- tion technology. Most office machines were much more humdrum: typewriters, record-keeping systems, and adding machines. Even more humdrum were the many varieties of office supplies available to American business: a hundred different types and grades of pencil; dozens of makes of fountain pens; paper clips, fasteners, and staplers of every conceivable variety; patented check-cutting machines to pre- vent fraud; cashier’s coin trays and gadgets for sorting cash; carbon paper and type- writer sundries; loose-leaf ledgers and filing cabinets; wooden desks equipped with pigeonholes. The list goes on and on.
In the closing decades of the nineteenth century, office equipment, in both its most advanced and its least sophisticated forms, was almost entirely an American phenomenon. Its like would not be seen in Europe until the new century and, in many businesses, not until after World War I.
There were two main reasons for America’s affinity for office machinery. First, because of the American office’s late start compared with Europe, it did not carry the albatross of old-fashioned offices and entrenched archaic working methods. For example, back in England, the British Prudential Assurance Company had been es- tablished in the 1850s with Victorian data-processing methods that it could not shake off because redesigning the office system to make use of typewriters, adding machines, or modern card index systems was never cost-effective. Indeed, there was not a single typewriter in the Prudential before the turn of the century, and it was not until 1915 that any advanced office machinery was introduced. By contrast, the American Prudential Company in New York, which was established twenty years after the British company, immediately made use of any office appliances on the market and became a recognized leader in utilizing office technology—a repu- tation it sustained right into the 1950s, when it was one of the first American of- fices to computerize. Similarly, while the British clearing houses were unmechanized until well into the new century, their American counterparts be- came massive users of Comptometers and Burroughs adding machines during the 1890s.
America’s Love Affair with Office Machinery 19
But no simple economic explanation can fully account for America’s love affair with office machinery. The fact is that America was gadget-happy and was caught up by the glamour of the mechanical office. American firms often bought office ap- pliances simply because they were perceived as modern—much as American firms bought the first computers in the 1950s. This attitude was reinforced by the rheto- ric of the office-systems movement.
Just as Frederick W. Taylor was pioneering scientific management in American in- dustry in the 1880s, focusing on the shop floor, a new breed of scientific manager— or “systematizer”—was beginning to revolutionize the American office. As an early systematizer puffed to his audience in 1886:
Now, administration without records is like music without notes—by ear. Good as far as it goes which is but a little way—it bequeathes nothing to the future. . . . Under rational management the accumulation of experience, and its systematic use and application, form the first fighting line.
Systematizers set about restructuring the office, introducing typewriters and adding machines, designing multipart business forms and loose-leaf filing systems, replac- ing old-fashioned accounting ledgers with machine billing systems, and so on. The office systematizer was the ancestor of today’s information-technology consultant.
Powered by the fad for office rationalization, the United States was the first country in the world to adopt office machinery on a large scale. This early start en- abled the United States to become the leading producer of information-technology goods, a position it has sustained to the present day. In turn, the United States dominated the typewriter, record-keeping, and adding-machine industries for most of their histories; it dominated the accounting-machine industry between the two world wars; it established the computer industry after World War II; and it leads the industry to this day. There is thus an unbroken line of descent from the giant office-machine firms of the 1890s to the computer makers of today.

2 THE MECHANICAL OFFICE
IN 1928 THE WORLD’S top four office-machine suppliers were Remington Rand, with annual sales of $60 million; National Cash Register (NCR), with sales of $50 million; the Burroughs Adding Machine Company, with $32 million worth of business; and—trailing the three leaders by a considerable margin—IBM, with an income of $20 million. Forty years later those same firms were among the top- ten computer manufacturers, and of the four, IBM, whose sales exceeded those of the other three combined, was the third-largest corporation in the world, with an- nual revenues of $21 billion and a workforce of a third of a million people.
To understand the development of the computer industry, and how this appar- ently new industry was shaped by the past, one must understand the rise of the office-machine giants in the years around the turn of the twentieth century. This understanding is necessary, above all, to appreciate how IBM’s managerial style, sales ethos, and technologies combined to make it perfectly adapted to shape and then dominate the computer industry.
Today, we use computers in the office for three main tasks. There is document preparation: for example, using a word-processing program to produce letters and reports. There is information storage: for example, using a database program to store names and addresses, or inventories. And there is financial analysis and ac- counting: for example, using a spreadsheet program for financial forecasting, or us- ing a computer to organize a company’s payroll.
These were precisely the three key office activities that the business-machine companies of the late nineteenth century were established to serve. Remington Rand was the leading supplier of typewriters for document preparation and filing systems for information storage. Burroughs dominated the market for adding ma- chines used for simple calculations. IBM dominated the market for punched-card accounting machines. And NCR, having started out making cash registers in the 1880s, also became a major supplier of accounting machines.

Who's Who The Wizards and their Machines
Bob Albrecht Found of People's Computer Company who took visceral pleasure in exposing youngsters to computers.
Altair 8800 The pioneering microcomputer that galvanized hardware hackers. Building this kit made you learn hacking. Then you tried to figure out what to DO with it.
Apple II ][ Steve Wozniak's friendly, flaky, good-looking computer, wildly successful and the spark and soul of a thriving industry.
Atari 800 This home computer gave great graphics to game hackers like John Harris, though the company that made it was loath to tell you how it worked.
Bob and Carolyn Box World-record-holding gold prospectors turned software stars, working for Sierra On-Line.
Doug Carlston Corporate lawyer who chucked it all to form the Broderbund software company.
Bob Davis Left job in liquor store to become best-selling author of Sierra On-Line computer game "Ulysses and the Golden Fleece." Success was his downfall.
Peter Deutsch Bad in sports, brilliant at math, Peter was still in short pants when he stubled on the TX-0 at MIT--and hacked it along with the masters.
Steve Dompier Homebrew member who first made the Altair sing, and later wrote the "Targe" game on the Sol which entranced Tom Snyder.
John Draper The notorious "Captain Crunch" who fearlessly explored the phone systems, got jailed, hacked microprocessors.
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
3
Cigarettes made his violent.
Mark Duchaineau The young Dungeonmaster who copy-protected On-Lines disks at his whim.
Chris Esponosa Fourteen-year-old follower of Steve Wozniak and early Apple employee.
Lee Felsenstein Former "military editor" of Berkeley Barb, and hero of an imaginary science-fiction novel, he designed computers with "junkyard" approach and was central figure in Bay Area hardware hacking in the seventies.
Ed Fredkin Gentle founder of Information International, thought himself world's greates programmer until he met Stew Nelson. Father figure to hackers.
Gordon French Silver-haired hardware hacker whose garage held not cars but his homebrewed Chicken Hawk comptuer, then held the first Homebrew Computer Club meeting.
Richard Garriott Astronaut's son who, as Lord British, created Ultima world on computer disks.
Bill Gates Cocky wizard, Harvard dropout who wrote Altair BASIC, and complained when hackers copied it.
Bill Gosper Horwitz of computer keyboards, master math and LIFE hacker at MIT AI lab, guru of the Hacker Ethic and student of Chinese restaurant menus.
Richard Greenblatt Single-minded, unkempt, prolific, and canonical MIT hacker who went into night phase so often that he zorched his academic career. The hacker's hacker.
John Harris The young Atari 800 game hacker who became Sierra On-Line's star programmer, but yearned for female companionship.
IBM-PC IBM's entry into the personal computer market which amazingly included a bit of the Hacker Ethic, and took over. [H.E. as open architecture.]
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
4
IBM 704 IBM was The Enemy, and this was its machine, the Hulking Giant computer in MIT's Building 26. Later modified into the IBM 709, then the IBM 7090. Batch-processed and intolerable.
Jerry Jewell Vietnam vet turned programmer who founded Sirius Software.
Steven Jobs Visionary, beaded, non-hacking youngster who took Wozniak's Apple II ][, made a lot of deals, and formed a company that would make a billion dollars.
Tom Knight At sixteen, an MIT hacker who would name the Incompatible Time-sharing System. Later a Greenblatt nemesis over the LISP machine schism.
Alan Kotok The chubby MIT student from Jersey who worked under the rail layout at TMRC, learned the phone system at Western Electric, and became a legendary TX-0 and PDP-1 hacker.
Effrem Lipkin Hacker-activist from New York who loved machines but hated their uses. Co-Founded Community Memory; friend of Felsenstein.
LISP Machine The ultimate hacker computer, invented mosly by Greenblatt and subject of a bitter dispute at MIT.
"Uncle" John McCarthy Absent-minded but brilliant MIT [later Stanford] professor who helped pioneer computer chess, artificial intelligence, LISP.
Bob Marsh Berkeley-ite and Homebrewer who shared garage with Felsenstein and founded Processor Technology, which made the Sol computer.
Roger Melen Homebrewer who co-founded Cromemco company to make circuit boards for Altair. His "Dazzler" played LIFE programs on his kitchen table.
Louis Merton Pseudonym for the AI chess hacker whose tendency to go catatonic brought the hacker community together.
Jude Milhon Met Lee Felsenstein through a classified ad in the
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
5
Berkeley Barb, and became more than a friend-- a member of the Community Memory collective.
Marvin Minsky Playful and brilliant MIT prof who headed the AI lave and allowed the hackers to run free.
Fred Moore Vagabond pacifist who hated money, loved technology, and co-founded Homebrew Club.
Stewart Nelson Buck-toothed, diminutive, but fiery AI lab hacker who connected the PDP-1 comptuer to hack the phone system. Later co-founded the Systems Concepts company.
Ted Nelson Self-described "innovator" and noted curmudgeon who self-published the influential Computer Lib book.
Russel Noftsker Harried administrator of MIT AI lab in the late sixties; later president of Symbolics company.
Adam Osborne Bangkok-born publisher-turned-computer-manufacturer who considered himself a philsopher. Founded Osborne Computer Company to make "adequate" machines.
PDP-1 Digital Equipment's first minicomputer, and in 1961 an interactive godsend to the MIT hackers and a slap in the face to IBM fascism.
PDP-6 Designed in part by Kotok, this mainframe computer was cornerstone of AI lab, with its gorgeious instruction set and sixteen sexy registers.
Tom Pittman The religious Homebrew hacker who lost his wife but kept the faith with his Tiny Basic.
Ed Roberts Enigmatic founder of MITS company who shook the world with his Altair computer. He wanted to help people build mental pyramids.
Steve [Slug] Russell McCarthy's "coolie," who hacked the Spacewar program, first videogame, on the PDP-1. Never made a dime from it.
Peter Samson
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
6
MIT hacker, one of the first, who loved systems, trains, TX-0, music, parliamentary procedure, pranks, and hacking.
Bob Saunders Jolly, balding TMRC hacker who married early, hacked till late at night eating "lemon gunkies," and mastered the "CBS Strategy on Spacewar.
Warren Schwader Big blond hacker from rural Wisconsin who went from the assembly line to software stardom but couldn't reconcile the shift with his devotion to Jehovah's Witnesses.
David Silver Left school at fourteen to be mascot of AI lab; maker of illicit keys and builder of a tiny robot that did the impossible.
Dan Sokol Long-haired prankster who reveled in revealing technological secrets at Homebrew Club. Helped "liberate" Alair BASIC on paper tape.
Les Solomon Editor of Popular Electroics, the puller of strings who set the computer revolution into motion.
Marty Spergel The Junk Man, the Homebrew member who supplied circuits and cables and could make you a deal for anything.
Richard Stallman The Last of the Hackers, who vowed to defend the principles of Hackerism to the bitter end. Remained at MIT until there was no one to eat Chinese food with.
Jeff Stephenson Thirty-year-old martial arts veteran and hacker who was astounded that joining Sierra On-Line meant enrolling in Summer Camp.
Jay Sullivan MAddeningly clam wizard-level programmer at Informatics who impressed Ken Williams by knowing the meaning of the word "any."
Dick Sunderland Chalk-complexioned MBA who believed that firm managerial bureaucracy was a worth goal, but as president of Sierra On-Line found that hackers didn't think that way.
Gerry Sussman Young MIT hacker branded "loser" because he smoked a pipe
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
7
and "munged" his programs; later became "winner" by algorithmic magic.
Margot Tommervik With her husband Al, long-haired Margot parlayed her game show winnings into a magazine that deified the Apple Computer.
Tom Swift Terminal Lee Felsenstein's legendary, never-to-be-built computer terminal which would give the user ultimate leave to get his hands on the world.
TX-0 Filled a small room, but in the late fifties this $3 million machine was the world's first personal computer--for the community of MIT hackers that formed around it.
Jim Warren Portly purveyor of "techno-gossip" at Homebrew, he was first editor of hippie-styled Dr. Dobbs Journal, later started the lucrative Computer Faire.
Randy Wigginton Fifteen-year-old member of Steve Wozniak's kiddie corps, he help Woz trundle the Apple II to Homebrew. Still in high school when he became Apple's first software employee.
Ken Williams Arrogant and brilliant young programmer who saw the writing on the CRT and started Sierra On-Line to make a killing and improve society by selling games for the Apple computer.
Roberta Williams Ken Williams' timid wife who rediscovered her own creativity by writing "Mystery House," the first of her many bestselling computer games.
Steven "Woz" Wozniak Openhearted, technologically daring hardware hacker from San Jose suburbs. Woz built the Apple Computer for the pleasure of himself and friends.
PART ONE True Hackers CAMBRIDGE: The Fifties and Sixties
CHAPTER 1 THE TECH MODEL RAILROAD CLUB
Just why Peter Samson was wandering around in Building 26 in the middle of the night is a matter that he would find difficult to explain. Some things are not spoken. If you were like the people whom Peter Samson was coming to know and befriend in this,
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
8
his freshman year at the Massachusetts Institute of Technology in the winter of 1958-59, no explanation would be required. Wandering around the labyrinth of laboratories and storerooms, searching for the secrets of telephone switching in machine rooms, tracing paths of wires or relays in subterranean steam tunnels . . . for some, it was common behavior, and there was no need to justify the impulse, when confronted with a closed door with an unbearably intriguing noise behind it, to open the door uninvited. And then, if there was no one to physically bar access to whatever was making that intriguing noise, to touch the machine, start flicking switches and noting responses, and eventually to loosen a screw, unhook a template, jiggle some diodes and tweak a few connections. Peter Samson and his friends had grown up with a specific relationship to the world, wherein things had meaning only if you found out how they worked. And how would you go about that if not by getting your hands on them?
It was in the basement of Building 26 that Samson and his friends discovered the EAM room. Building 26 was a long glass-and-steel structure, one of MIT's newer buildings, contrasting with the venerable pillared structures that fronted the Institute on Massachusetts Avenue. In the basement of this building void of personality, the EAM room. Electronic Accounting Machinery. A room that housed machines which ran like computers.
Not many people in 1959 had even seen a computer, let alone touched one. Samson, a wiry, curly-haired redhead with a way of extending his vowels so that it would seem he was racing through lists of possible meanings of statements in mid-word, had viewed computers on his visits to MIT from his hometown of Lowell, Massachusetts, less than thirty miles from campus. This made him a "Cambridge urchin," one of dozens of science-crazy high schoolers in the region who were drawn, as if by gravitational
pull, to the Cambridge campus. He had even tried to rig up his own computer with discarded parts of old pinball machines: they were the best source of logic elements he could find.
LOGIC ELEMENTS: the term seems to encapsulate what drew Peter Samson, son of a mill machinery repairman, to electronics. The subject made sense. When you grow up with an insatiable curiosity as to how things work, the delight you find upon discovering something as elegant as circuit logic, where all connections have to complete their loops, is profoundly
thrilling. Peter Samson, who early on appreciated the mathematical simplicity of these things, could recall seeing a television show on Boston's public TV channel, WGBH, which gave a rudimentary introduction to programming a computer in its own language. It fired his imagination: to Peter Samson, a computer was surely like Aladdin's lamp--rub it, and it would do your bidding. So he tried to learn more about the field, built machines of his own, entered science project competitions and contests, and went to the place that people of his ilk aspired to: MIT. The repository of the very brightest of those weird
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
9
high school kids with owl-like glasses and underdeveloped pectorals who dazzled math teachers and flunked PE, who dreamed not of scoring on prom night, but of getting to the finals of the General Electric Science Fair competition. MIT, where he would wander the hallways at two o'clock in the morning, looking for something interesting, and where he would indeed discover something that would help draw him deeply into a new form of creative process, and a new life-style, and would put him into the forefront of a society envisioned only by a few science-fiction writers of mild disrepute. He would discover a computer that he could play with.
The EAM room which Samson had chanced on was loaded with large keypunch machines the size of squat file cabinets. No one was protecting them: the room was staffed only by day, when a select group who had attained official clearance were privileged enough
to submit long manila cards to operators who would then use these machines to punch holes in them according to what data the privileged ones wanted entered on the cards. A hole in the card would represent some instruction to the computer, telling it to
put a piece of data somewhere, or perform a function on a piece of data, or move a piece of data from one place to another. An entire stack of these cards made one computer program, a program being a series of instructions which yield some expected result,
just as the instructions in a recipe, when precisely followed, lead to a cake. Those cards would be taken to yet another operator upstairs who would feed the cards into a "reader" that would note where the holes were and dispatch this information to the IBM 704 computer on the first floor of Building 26. The Hulking Giant.
The IBM 704 cost several million dollars, took up an entire room, needed constant attention from a cadre of professional machine operators, and required special air-conditioning so that the glowing vacuum tubes inside it would not heat up to data-destroying temperatures. When the air-conditioning broke down--a fairly common occurrences--a loud gong would sound, and three engineers would spring from a nearby office to frantically take covers off the machine so its innards wouldn't melt. All
these people in charge of punching cards, feeding them into readers, and pressing buttons and switches on the machine were what was commonly called a Priesthood, and those privileged enough to submit data to those most holy priests were the official acolytes. It was an almost ritualistic exchange.
ACOLYTE: Oh machine, would you accept my offer of information so you may run my program and perhaps give me a computation?
PRIEST (on behalf of the machine): We will try. We promise nothing.
As a general rule, even these most privileged of acolytes were not allowed direct access to the machine itself, and they would
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
10
not be able to see for hours, sometimes for days, the results of the machine's ingestion of their "batch" of cards.
This was something Samson knew, and of course it frustrated the hell out of Samson, who wanted to get at the damn machine. For this was what life was all about.
What Samson did not know, and was delighted to discover, was that the EAM room also had a particular keypunch machine called the 407. Not only could it punch cards, but it could also read cards, sort them, and print them on listings. No one seemed to
be guarding these machines, which were computers, sort of. Of course, using them would be no picnic: one needed to actually wire up what was called a plug board, a two-inch-by-two-inch plastic square with a mass of holes in it. If you put hundreds
of wires through the holes in a certain order, you would get something that looked like a rat's nest but would fit into this electromechanical machine and alter its personality. It could do what you wanted it to do.
So, without any authorization whatsoever, that is what Peter Samson set out to do, along with a few friends of his from an MIT organization with a special interest in model railroading. It was a casual, unthinking step into a science-fiction future, but that was typical of the way that an odd subculture was pulling itself up by its bootstraps and growing to underground prominence--to become a culture that would be the impolite, unsanctioned soul of computerdom. It was among the first computer hacker escapades of the Tech Model Railroad Club, or TMRC.
***
Peter Samson had been a member of the Tech Model Railroad Club since his first week at MIT in the fall of 1958. The first event that entering MIT freshmen attended was a traditional welcoming lecture, the same one that had been given for as long as anyone
at MIT could remember. LOOK AT THE PERSON TO YOUR LEFT . . . LOOK AT THE PERSON TO YOUR RIGHT . . . ONE OF YOU THREE WILL NOT GRADUATE FROM THE INSTITUTE. The intended effect of the speech was to create that horrid feeling in the back of the collective freshman throat that signaled unprecedented dread. All their lives, these freshmen had been almost exempt from academic pressure. The exemption had been earned by virtue of brilliance. Now each of them had a person to the right and a person to the left who was just as smart. Maybe even smarter.
But to certain students this was no challenge at all. To these youngsters, classmates were perceived in a sort of friendly haze: maybe they would be of assistance in the consuming quest to find out how things worked, and then to master them. There were enough obstacles to learning already--why bother with stupid things like brown-nosing teachers and striving for grades? To
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
11
students like Peter Samson, the quest meant more than the degree.
Sometime after the lecture came Freshman Midway. All the campus organizations--special-interest groups, fraternities, and such-- set up booths in a large gymnasium to try to recruit new members. The group that snagged Peter was the Tech Model Railroad Club.
Its members, bright-eyed and crew-cutted upperclassmen who spoke with the spasmodic cadences of people who want words out of the way in a hurry, boasted a spectacular display of HO gauge trains they had in a permanent clubroom in Building 20. Peter Samson
had long been fascinated by trains, especially subways. So he went along on the walking tour to the building, a shingle-clad temporary structure built during World War II. The hallways were cavernous, and even though the clubroom was on the second floor it had the dank, dimly lit feel of a basement.
The clubroom was dominated by the huge train layout. It just about filled the room, and if you stood in the little control area called "the notch" you could see a little town, a little industrial area, a tiny working trolley line, a papier-mache mountain, and of course a lot of trains and tracks. The trains were meticulously crafted to resemble their full-scale counterparts, and they chugged along the twists and turns of track with picture-book perfection.
And then Peter Samson looked underneath the chest-high boards which held the layout. It took his breath away. Underneath this layout was a more massive matrix of wires and relays,and crossbar switches than Peter Samson had ever dreamed existed. There were neat regimental lines of switches, and achingly regular rows of
dull bronze relays, and a long, rambling tangle of red, blue, and yellow wires--twisting and twirling like a rainbow-colored explosion of Einstein's hair. It was an incredibly complicated system, and Peter Samson vowed to find out how it worked.
The Tech Model Railroad Club awarded its members a key to the clubroom after they logged forty hours of work on the layout. Freshman Midway had been on a Friday. By Monday, Peter Samson had his key.
***
There were two factions of TMRC. Some members loved the idea of spending their time building and painting replicas of certain trains with historical and emotional value, or creating realistic scenery for the layout. This was the knife-and-paintbrush contingent, and it subscribed to railroad magazines and booked
the club for trips on aging train lines. The other faction centered on the Signals and Power Subcommittee of the club, and it cared far more about what went on under the layout. This was The System, which worked something like a collaboration between Rube Goldberg and Wernher von Braun, and it was constantly being improved, revamped, perfected, and sometimes "gronked"--in club
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
12
jargon, screwed up. S&P people were obsessed with the way The System worked, its increasing complexities, how any change you made would affect other parts, and how you could put those relationships between the parts to optimal use.
Many of the parts for The System had been donated by the Western Electric College Gift Plan, directly from the phone company. The club's faculty advisor was also in charge of the campus phone system, and had seen to it that sophisticated phone equipment was available for the model railroaders. Using that equipment as a starting point, the Railroaders had devised a scheme which
enabled several people to control trains at once, even if the trains were at different parts of the same track. Using dials appropriated from telephones, the TMRC "engineers" could specify which block of track they wanted control of, and run a train from there. This was done by using several types of phone company relays, including crossbar executors and step switches which let you actually hear the power being transferred from one block to another by an other-worldly chunka-chunka-chunka sound.
It was the S&P group who devised this fiendishly ingenious scheme, and it was the S&P group who harbored the kind of restless curiosity which led them to root around campus buildings in search of ways to get their hands on computers. They were lifelong disciples of a Hands-On Imperative. Head of S&P was an upperclassman named Bob Saunders, with ruddy, bulbous features, an infectious laugh, and a talent for switch gear. As a child in Chicago, he had built a high-frequency transformer for a high school project; it was his six-foot-high version of a Tesla coil, something devised by an engineer in the 1800s which was supposed to send out furious waves of electrical power. Saunders said his coil project managed to blow out television reception for blocks around. Another person who gravitated to S&P was Alan Kotok, a plump, chinless, thick-spectacled New Jerseyite in Samson's
class. Kotok's family could recall him, at age three, prying a plug out of a wall with a screwdriver and causing a hissing shower of sparks to erupt. When he was six, he was building and wiring lamps. In high school he had once gone on a tour of the Mobil Research Lab in nearby Haddonfield, and saw his first computer--the exhilaration of that experience helped him decide to enter MIT. In his freshman year, he earned a reputation as one of TMRC's most capable S&P people.
The S&P people were the ones who spent Saturdays going to Eli Heffron's junkyard in Somerville scrounging for parts, who would spend hours on their backs resting on little rolling chairs they called "bunkies" to get underneath tight spots in the switching system, who would work through the night making the wholly unauthorized connection between the TMRC phone and the East Campus. Technology was their playground.
The core members hung out at the club for hours; constantly improving The System, arguing about what could be done next,
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
13
developing a jargon of their own that seemed incomprehensible to outsiders who might chance on these teen-aged fanatics, with their checked short-sleeve shirts, pencils in their pockets, chino pants, and, always, a bottle of Coca-Cola by their side. (TMRC purchased its own Coke machine for the then forbidding sum of $165; at a tariff of five cents a bottle, the outlay was
replaced in three months; to facilitate sales, Saunders built a change machine for Coke buyers that was still in use a decade later.) When a piece of equipment wasn't working, it was "losing"; when a piece of equipment was ruined, it was "munged" (Mash Until No Good); the two desks in the corner of the room were not called the office, but the "orifice"; one who insisted
on studying for courses was a "tool"; garbage was called "cruft"; and a project undertaken or a product built not solely to fulfill some constructive goal, but with some wild pleasure taken in mere involvement, was called a "hack."
This latter term may have been suggested by ancient MIT lingo-- the word "hack" had long been used to describe the elaborate college pranks that MIT students would regularly devise, such as covering the dome that overlooked the campus with reflecting foil. But as the TMRC people used the word, there was serious respect implied. While someone might call a clever connection between relays a "mere hack," it would be understood that, to qualify as a hack, the feat must be imbued with innovation, style, and technical virtuosity. Even though one might self-deprecatingly say he was "hacking away at The System" (much as an axe-wielder hacks at logs), the artistry with which one hacked was recognized to be considerable.
The most productive people working on Signals and Power called themselves "hackers" with great pride. Within the confines of the clubroom in Building 20, and of the "Tool Room" (where some study and many techno bull sessions took place), they had unilaterally endowed themselves with the heroic attributes of Icelandic legend. This is how Peter Samson saw himself and his friends in a Sandburg-esque poem in the club newsletter:
Switch Thrower for the World, Fuze Tester, Maker of Routes, Player with the Railroads and the System's Advance Chopper; Grungy, hairy, sprawling, Machine of the Point-Function Line-o-lite: They tell me you are wicked and I believe them; for I have seen
your painted light bulbs under the lucite luring
the system coolies . . . Under the tower, dust all over the place, hacking with bifur-
cated springs . . . Hacking even as an ignorant freshman acts who has never lost
occupancy and has dropped out Hacking the M-Boards, for under its locks are the switches, and
under its control the advance around the layout, Hacking!
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
14
Hacking the grungy, hairy, sprawling hacks of youth; uncabled, frying diodes, proud to be Switch-thrower, Fuze- tester, Maker of Routes, Player with Railroads, and Advance Chopper to the System.
Whenever they could, Samson and the others would slip off to the EAM room with their plug boards, trying to use the machine to keep track of the switches underneath the layout. Just as important, they were seeing what the electromechanical counter could do, taking it to its limit.
That spring of 1959, a new course was offered at MIT. It was the first course in programming a computer that freshmen could take. The teacher was a distant man with a wild shock of hair and an equally unruly beard--John McCarthy. A master mathematician, McCarthy was a classically absent-minded professor; stories abounded about his habit of suddenly answering a question hours, sometimes even days after it was first posed to him. He would approach you in the hallway, and with no salutation would begin speaking in his robotically precise diction, as if the pause in conversation had been only a fraction of a second, and not a week. Most likely, his belated response would be brilliant.
McCarthy was one of a very few people working in an entirely new form of scientific inquiry with computers. The volatile and controversial nature of his field of study was obvious from the very arrogance of the name that McCarthy had bestowed upon it: Artificial Intelligence. This man actually thought that
computers could be SMART. Even at such a science-intensive place as MIT, most people considered the thought ridiculous: they considered computers to be useful, if somewhat absurdly expensive, tools for number-crunching huge calculations and for devising missile defense systems (as MIT's largest computer, the Whirlwind, had done for the early-warning SAGE system), but scoffed at the thought that computers themselves could actually
be a scientific field of study, Computer Science did not officially exist at MIT in the late fifties, and McCarthy and his fellow computer specialists worked in the Electrical Engineering Department, which offered the course, No. 641, that Kotok, Samson, and a few other TRMC members took that spring.
McCarthy had started a mammoth program on the IBM 704--the Hulking Giant--that would give it the extraordinary ability to play chess. To critics of the budding field of Artificial Intelligence, this was just one example of the boneheaded optimism of people like John McCarthy. But McCarthy had a certain vision of what computers could do, and playing chess was only the beginning.
All fascinating stuff, but not the vision that was driving Kotok and Samson and the others. They wanted to learn how to WORK the damn machines, and while this new programming language called LISP that McCarthy was talking about in 641 was interesting, it
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
15
was not nearly as interesting as the act of programming, or that fantastic moment when you got your printout back from the Priesthood--word from the source itself!--and could then spend hours poring over the results of the program, what had gone wrong with it, how it could be improved. The TMRC hackers were devising ways to get into closer contact with the IBM 704, which soon was upgraded to a newer model called the 709. By hanging out at the computation center in the wee hours of the morning,
and by getting to know the Priesthood, and by bowing and scraping the requisite number of times, people like Kotok were eventually allowed to push a few buttons on the machine, and watch the lights as it worked.
There were secrets to those IBM machines that had been painstakingly learned by some of the older people at MIT with access to the 704 and friends among the Priesthood. Amazingly, a few of these programmers, grad students working with McCarthy, had even written a program that utilized one of the rows of tiny lights: the lights would be lit in such an order that it looked like a little ball was being passed from right to left: if an operator hit a switch at just the right time, the motion of the lights could be reversed--Computer Ping-Pong! This obviously was the kind of thing that you'd show off to impress your peers, who would then take a look at the actual program you had written and see how it was done.
To top the program, someone else might try to do the same thing with fewer instructions--a worthy endeavor, since there was so little room in the small "memory" of the computers of those days that not many instructions could fit into them, John McCarthy had once noticed how his graduate students who loitered around the 704 would work over their computer programs to get the most out of the fewest instructions, and get the program compressed so that fewer cards would need to be fed to the machine. Shaving off an instruction or two was almost an obsession with them. McCarthy compared these students to ski bums. They got the same kind of primal thrill from "maximizing code" as fanatic skiers
got from swooshing frantically down a hill. So the practice of taking a computer program and trying to cut off instructions without affecting the outcome came to be called "program bumming," and you would often hear people mumbling things like "Maybe I can bum a few instructions out and get the octal correction card loader down to three cards instead of four."
McCarthy in 1959 was turning his interest from chess to a new way of talking to the computer, the whole new "language" called LISP. Alan Kotok and his friends were more than eager to take over the chess project. Working on the batch-processed IBM, they embarked on the gargantuan project of teaching the 704, and later the 709, and even after that its replacement the 7090, how to play the
game of kings. Eventually Kotok's group became the largest users of computer time in the entire MIT computation center.
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
16
Still, working with the IBM machine was frustrating. There was nothing worse than the long wait between the time you handed in your cards and the time your results were handed back to you. If you had misplaced as much as one letter in one instruction, the program would crash, and you would have to start the whole process over again. It went hand in hand with the stifling proliferation of goddamn RULES that permeated the atmosphere of the computation center. Most of the rules were designed to keep crazy young computer fans like Samson and Kotok and Saunders physically distant from the machine itself. The most rigid rule
of all was that no one should be able to actually touch or tamper with the machine itself. This, of course, was what those Signals and Power people were dying to do more than anything else in the world, and the restrictions drove them mad.
One priest--a low-level sub-priest, really--on the late-night shift was particularly nasty in enforcing this rule, so Samson devised a suitable revenge. While poking around at Eli's electronic junk shop one day, he chanced upon an electrical board precisely like the kind of board holding the clunky vacuum tubes which resided inside the IBM. One night, sometime before 4 A.M., this particular sub-priest stepped out for a minute; when he returned, Samson told him that the machine wasn't working, but they'd found the trouble--and held up the totally smashed module from the old 704 he'd gotten at Eli's.
The sub-priest could hardly get the words out. "W-where did you get that?"
Samson, who had wide green eyes that could easily look maniacal, slowly pointed to an open place on the machine rack where, of course, no board had ever been, but the space still looked sadly bare. The sub-priest gasped. He made faces that indicated his bowels were about to give out. He whimpered exhortations to the deity. Visions, no doubt, of a million-dollar deduction from his paycheck began flashing before him. Only after his supervisor, a high priest with some understanding of the mentality of these young wiseguys from the Model Railroad Club, came and explained the situation did he calm down.
He was not the last administrator to feel the wrath of a hacker thwarted in the quest for access.
***
One day a former TMRC member who was now on the MIT faculty paid a visit to the clubroom. His name was Jack Dennis. When he had been an undergraduate in the early 1950s, he had worked furiously underneath the layout. Dennis lately had been working a computer which MIT had just received from Lincoln Lab, a military
development laboratory affiliated with the Institute. The computer was called the TX-0, and it was one of the first transistor-run computers in the world. Lincoln Lab had used it
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
17
specifically to test a giant computer called the TX-2, which had a memory so complex that only with this specially built little brother could its ills be capably diagnosed. Now that its original job was over, the three-million-dollar TX-0 had been shipped over to the Institute on "long-term loan," and apparently no one at Lincoln Lab had marked a calendar with a return date. Dennis asked the S&P people at TMRC whether they would like to see it.
Hey you nuns! Would you like to meet the Pope?
The TX-0 was in Building 26, in the second-floor Radio Laboratory of Electronics (RLE), directly above the first-floor Computation Center which housed the hulking IBM 704. The RLE lab resembled the control room of an antique spaceship. The TX-0, or Tixo, as it was sometimes called, was for its time a midget machine, since it was one of the first computers to use finger-size transistors instead of hand-size vacuum tubes. Still, it took up much of the room, along with its fifteen tons of supporting air-conditioning equipment. The TX-O's workings were mounted on several tall, thin chassis, like rugged metal bookshelves, with tangled wires and neat little rows of tiny, bottle-like containers in which the transistors were inserted. Another rack had a solid metal front speckled with grim-looking gauges. Facing the racks was an L-shaped console, the control panel of this H. G. Wells
spaceship, with a blue countertop for your elbows and papers. On the short arm of the L stood a Flexowriter, which resembled a typewriter converted for tank warfare, its bottom anchored in a military gray housing. Above the top were the control panels, boxlike protrusions painted an institutional yellow. On the
sides of the boxes which faced the user were a few gauges, several lines of quarter-inch blinking lights, a matrix of steel toggle switches the size of large grains of rice, and, best of all, an actual cathode ray tube display, round and smoke-gray.
The TMRC people were awed. THIS MACHINE DID NOT USE CARDS. The user would first punch in a program onto a long, thin paper tape with a Flexowriter (there were a few extra Flexowriters in an adjoining room), then sit at the console, feed in the program by
running the tape through a reader, and be able to sit there while the program ran. If something went wrong with the program, you knew immediately, and you could diagnose the problem by using some of the switches, or checking out which of the lights were blinking or lit. The computer even had an audio output: while
the program ran, a speaker underneath the console would make a sort of music, like a poorly tuned electric organ whose notes would vibrate with a fuzzy, ethereal din. The chords on this "organ" would change, depending on what data the machine was reading at any given microsecond; after you were familiar with the tones, you could actually HEAR what part of your program the computer was working on. You would have to discern this, though, over the clacking of the Flexowriter, which could make you think you were in the middle of a machine-gun battle. Even more
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
18
amazing was that, because of these "interactive" capabilities, and also because users seemed to be allowed blocks of time to use the TX-0 all by themselves, you could even modify a program WHILE SITTING AT THE COMPUTER. A miracle!
There was no way in hell that Kotok, Saunders, Samson, and the others were going to be kept away from that machine. Fortunately, there didn't seem to be the kind of bureaucracy surrounding the TX-0 that there was around the IBM 704. No cadre of officious priests. The technician in charge was a canny white-haired Scotsman named John McKenzie. While he made sure that graduate students and those working on funded projects-- Officially Sanctioned Users--maintained access to the machine, McKenzie tolerated the crew of TMRC madmen who began to hang out in the RLE lab, where the TX-0 stood.
Samson, Kotok, Saunders, and a freshman named Bob Wagner soon figured out that the best time of all to hang out in Building 26 was at night, when no person in his right mind would have signed up for an hour-long session on the piece of paper posted every Friday beside the air conditioner in the RLE lab. The TX-0 as a
rule was kept running twenty-four hours a day--computers back then were too expensive for their time to be wasted by leaving them idle through the night, and besides, it was a hairy procedure to get the thing up and running once it was turned off. So the TMRC hackers, who soon were referring to themselves as TX-0 hackers, changed their life-style to accommodate the computer. They laid claim to what blocks of time they could, and would "vulture time" with nocturnal visits to the lab on the off chance that someone who was scheduled for a 3 A.M. session might not show up.
"Oh!" Samson would say delightedly, a minute or so after someone failed to show up at the time designated in the logbook. "Make sure it doesn't go to waste!"
It never seemed to, because the hackers were there almost all the time. If they weren't in the RLE lab waiting for an opening to occur, they were in the classroom next to the TMRC clubroom, the Tool Room, playing a "hangman"-style word game that Samson had devised called "Come Next Door," waiting for a call from someone who was near the TX-0, monitoring it to see if someone had not shown up for a session. The hackers recruited a network of informers to give advance notice of potential openings at the computer--if a research project was not ready with its program in time, or a professor was sick, the word would be passed to TMRC and the hackers would appear at the TX-0, breathless and ready to jam into the space behind the console.
Though Jack Dennis was theoretically in charge of the operation, Dennis was teaching courses at the time, and preferred to spend the rest of his time actually writing code for the machine. Dennis played the role of benevolent godfather to the hackers:
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
19
he would give them a brief hands-on introduction to the machine, point them in certain directions, be amused at their wild programming ventures. He had little taste for administration, though, and was just as happy to let John McKenzie run things. McKenzie early on recognized that the interactive nature of the TX-0 was inspiring a new form of computer programming, and the hackers were its pioneers. So he did not lay down too many edicts.
The atmosphere was loose enough in 1959 to accommodate the strays--science-mad people whose curiosity burned like a hunger, who like Peter Samson would be exploring the uncharted maze of laboratories at MIT. The noise of the air-conditioning, the
audio output, and the drill-hammer Flexowriter would lure these wanderers, who'd poke their heads into the lab like kittens peering into baskets of yarn.
One of those wanderers was an outsider named Peter Deutsch. Even before discovering the TX-0, Deutsch had developed a fascination for computers. It began one day when he picked up a manual that someone had discarded, a manual for an obscure form of computer language for doing calculations. Something about the orderliness
of the computer instructions appealed to him: he would later describe the feeling as the same kind of eerily transcendent recognition that an artist experiences when he discovers the medium that is absolutely right for him. THIS IS WHERE I BELONG. Deutsch tried writing a small program, and, signing up for time under the name of one of the priests, ran it on a computer.
Within weeks, he had attained a striking proficiency in programming. He was only twelve years old.
He was a shy kid, strong in math and unsure of most everything else. He was uncomfortably overweight, deficient in sports, but an intellectual star performer. His father was a professor at MIT, and Peter used that as his entree to explore the labs.
It was inevitable that he would be drawn to the TX-0. He first wandered into the small "Kluge Room" (a "kluge" is a piece of inelegantly constructed equipment that seems to defy logic by working properly), where three off-line Flexowriters were available for punching programs onto paper tape which would later be fed into the TX-0. Someone was busy punching in a tape. Peter watched for a while, then began bombarding the poor soul with questions about that weird-looking little computer in the
next room. Then Peter went up to the TX-0 itself, examined it closely, noting how it differed from other computers: it was smaller, had a CRT display, and other neat toys. He decided right then to act as if he had a perfect right to be there. He got hold of a manual and soon was startling people by spouting actual make-sense computer talk, and eventually was allowed to sign up for night and weekend sessions, and to write his own programs.
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
20
McKenzie worried that someone might accuse him of running some sort of summer camp, with this short-pants little kid, barely tall enough to stick his head over the TX-O's console, staring at the code that an Officially Sanctioned User, perhaps some self-important graduate student, would be hammering into the Flexowriter, and saying in his squeaky, preadolescent voice something like "Your problem is that this credit is wrong over
here . . . you need this other instruction over there," and the self-important grad student would go crazy--WHO IS THIS LITTLE WORM?--and start screaming at him to go out and play somewhere. Invariably, though, Peter Deutsch's comments would turn out to be correct. Deutsch would also brazenly announce that he was going to write better programs than the ones currently available, and
he would go and do it.
Samson, Kotok, and the other hackers accepted Peter Deutsch: by virtue of his computer knowledge he was worthy of equal treatment. Deutsch was not such a favorite with the Officially Sanctioned Users, especially when he sat behind them ready to spring into action when they made a mistake on the Flexowriter. These Officially Sanctioned Users appeared at the TX-0 with the regularity of commuters. The programs they ran were statistical analyses, cross correlations, simulations of an interior of the nucleus of a cell. Applications. That was fine for Users, but
it was sort of a waste in the minds of the hackers. What hackers had in mind was getting behind the console of the TX-0 much in the same way as getting in behind the throttle of a plane, Or, as Peter Samson, a classical music fan, put it, computing with the TX-0 was like playing a musical instrument: an absurdly expensive musical instrument upon which you could improvise, compose, and, like the beatniks in Harvard Square a mile away, wail like a banshee with total creative abandon.
One thing that enabled them to do this was the programming system devised by Jack Dennis and another professor, Tom Stockman. When the TX-0 arrived at MIT, it had been stripped down since its days at Lincoln Lab: the memory had been reduced considerably, to
4,096 "words" of eighteen bits each. (A "bit" is a BInary digiT, either a one or zero. These binary numbers are the only thing computers understand. A series of binary numbers is called a "word.") And the TX-0 had almost no software. So Jack Dennis, even before he introduced the TMRC people to the TX-0, had been writing "systems programs"--the software to help users utilize
the machine.
The first thing Dennis worked on was an assembler. This was something that translated assembly language--which used three- letter symbolic abbreviations that represented instructions to the machine--into machine language, which consisted of the binary numbers 0 and 1. The TX-0 had a rather limited assembly language: since its design allowed only two bits of each eighteen-bit word to be used for instructions to the computer,
only four instructions could be used (each possible two-bit
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
21
variation--00, 0 1, 10, and 11--represented an instruction). Everything the computer did could be broken down to the execution of one of those four instructions: it took one instruction to add two numbers, but a series of perhaps twenty instructions to multiply two numbers. Staring at a long list of computer commands written as binary numbers--for example, 10011001100001-- could make you into a babbling mental case in a matter of minutes. But the same command in assembly language might look like this: ADD Y. After loading the computer with the assembler that Dennis wrote, you could write programs in this simpler symbolic form, and wait smugly while the computer did the translation into binary for you, Then you'd feed that binary "object" code back into the computer. The value of this was incalculable: it enabled programmers to write in something that LOOKED like code, rather than an endless, dizzying series of ones and zeros.
The other program that Dennis worked on with Stockman was something even newer--a debugger. The TX-0 came with a debugging program called UT-3, which enabled you to talk to the computer while it was running by typing commands directly into the Flexowriter, But it had terrible problems-for one thing, it only accepted typed-in code that used the octal numeric system. "Octal" is a base-eight number system (as opposed to binary, which is base two, and Arabic--ours-which is base ten), and it is a difficult system to use. So Dennis and Stockman decided to write something better than UT-3 which would enable users to use the symbolic, easier-to-work-with assembly language. This came to be called FLIT, and it allowed users to actually find program bugs during a session, fix them, and keep the program running. (Dennis would explain that "FLIT" stood for FLexowriter Interrogation Tape, but clearly the name's real origin was the insect spray with that brand name.) FLIT was a quantum leap forward, since it liberated programmers to actually do original composing on the machine--just like musicians composing on their musical instruments. With the use of the debugger, which took up one third of the 4,096 words of the TX-O's memory, hackers were free to create a new, more daring style of programming.
And what did these hacker programs DO? Well, sometimes, it didn't matter much at all what they did. Peter Samson hacked the night away on a program that would instantly convert Arabic numbers to Roman numerals, and Jack Dennis, after admiring the skill with which Samson had accomplished this feat, said, "My God, why would anyone want to do such a thing?" But Dennis knew why. There was ample justification in the feeling of power and accomplishment Samson got when he fed in the paper tape, monitored the lights and switches, and saw what were once plain old blackboard Arabic numbers coming back as the numerals the Romans had hacked with.
In fact it was Jack Dennis who suggested to Samson that there were considerable uses for the TX-O's ability to send noise to
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
22
the audio speaker. While there were no built-in controls for pitch, amplitude, or tone character, there was a way to control the speaker--sounds would be emitted depending on the state of the fourteenth bit in the eighteen-bit words the TX-0 had in its accumulator in a given microsecond. The sound was on or off depending on whether bit fourteen was a one or zero. So Samson set about writing programs that varied the binary numbers in that slot in different ways to produce different pitches.
At that time, only a few people in the country had been experimenting with using a computer to output any kind of music, and the methods they had been using required massive computations before the machine would so much as utter a note, Samson, who reacted with impatience to those who warned he was attempting the impossible, wanted a computer playing music right away. So he learned to control that one bit in the accumulator so adeptly that he could command it with the authority of Charlie Parker on the saxophone. In a later version of this music compiler, Samson rigged it so that if you made an error in your programming syntax, the Flexowriter would switch to a red ribbon and print "To err is human to forgive divine."
When outsiders heard the melodies of Johann Sebastian Bach in a single-voice, monophonic square wave, no harmony, they were universally unfazed. Big deal! Three million dollars for this giant hunk of machinery, and why shouldn't it do at least as much as a five-dollar toy piano? It was no use to explain to these outsiders that Peter Samson had virtually bypassed the process by which music had been made for eons. Music had always been made by directly creating vibrations that were sound. What happened
in Samson's program was that a load of numbers, bits of information fed into a computer, comprised a code in which the music resided. You could spend hours staring at the code, and not be able to divine where the music was. It only became music while millions of blindingly brief exchanges of data were taking place in the accumulator sitting in one of the metal, wire, and silicon racks that comprised the TX-0. Samson had asked the computer, which had no apparent knowledge of how to use a voice, to lift itself in song--and the TX-0 had complied.
So it was that a computer program was not only metaphorically a musical composition--it was LITERALLY a musical composition! It looked like--and was--the same kind of program which yielded complex arithmetical computations and statistical analyses. These digits that Samson had jammed into the computer were a universal language which could produce ANYTHING--a Bach fugue or an anti-aircraft system.
Samson did not say any of this to the outsiders who were unimpressed by his feat. Nor did the hackers themselves discuss this--it is not even clear that they analyzed the phenomenon in such cosmic terms. Peter Samson did it, and his colleagues appreciated it, because it was obviously a neat hack. That was
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
23
justification enough. ***
To hackers like Bob Saunders--balding, plump, and merry disciple of the TX-0, president of TMRC's S&P group, student of systems-- it was a perfect existence. Saunders had grown up in the suburbs of Chicago, and for as long as he could remember the workings of electricity and telephone circuitry had fascinated him. Before beginning MIT, Saunders had landed a dream summer job, working for the phone company installing central office equipment, He would spend eight blissful hours with soldering iron and pliers
in hand, working in the bowels of various systems, an idyll broken by lunch hours spent in deep study of phone company manuals. It was the phone company equipment underneath the TMRC layout that had convinced Saunders to become active in the Model Railroad Club.
Saunders, being an upperclassman, had come to the TX-0 later in his college career than Kotok and Samson: he had used the breathing space to actually lay the foundation for a social life, which included courtship of and eventual marriage to Marge French, who had done some non-hacking computer work for a research project. Still, the TX-0 was the center of his college career, and he shared the common hacker experience of seeing his grades suffer from missed classes. It didn't bother him much, because he knew that his real education was occurring in Room 240 of Building 26, behind the Tixo console. Years later he would describe himself and the others as "an elite group. Other people were off studying, spending their days up on four-floor buildings making obnoxious vapors or off in the physics lab throwing
particles at things or whatever it is they do. And we were simply not paying attention to what other folks were doing because we had no interest in it. They were studying what they were studying and we were studying what we were studying. And the fact that much of it was not on the officially approved curriculum was by and large immaterial."
The hackers came out at night. It was the only way to take full advantage of the crucial "off-hours" of the TX-0. During the day, Saunders would usually manage to make an appearance in a class or two. Then some time spent performing "basic maintenance"--things like eating and going to the bathroom. He might see Marge for a while. But eventually he would filter over to Building 26. He would go over some of the programs of the night before, printed on the nine-and-a-half-inch-wide paper that the Flexowriter used. He would annotate and modify the listing to update the code to whatever he considered the next stage of operation. Maybe then he would move over to the Model Railroad Club, and he'd swap his program with someone, checking simultaneously for good ideas and potential bugs. Then back to Building 26, to the Kluge Room next to the TX-0, to find an off-line Flexowriter on which to update his code. All the while
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
24
he'd be checking to see if someone had canceled a one-hour session on the machine; his own session was scheduled at something like two or three in the morning. He'd wait in the Kluge Room, or play some bridge back at the Railroad Club, until the time came.
Sitting at the console, facing the metal racks that held the computer's transistors, each transistor representing a location that either held or did not hold a bit of memory, Saunders would set up the Flexowriter, which would greet him with the word "WALRUS." This was something Samson had hacked, in honor of Lewis Carroll's poem with the line "The time has come, the Walrus said . . ." Saunders might chuckle at that as he went into the drawer for the paper tape which held the assembler program and fed that into the tape reader. Now the computer would be ready to assemble his program, so he'd take the Flexowriter tape he'd been working on and send that into the computer. He'd watch the lights go on as the computer switched his code from "source" (the symbolic assembly language) to "object" code (binary), which the computer would punch out into another paper tape. Since that tape was in the object code that the TX-0 understood, he'd feed it in, hoping that the program would run magnificently.
There would most probably be a few fellow hackers kibitzing behind him, laughing and joking and drinking Cokes and eating some junk food they'd extracted from the machine downstairs. Saunders preferred the lemon jelly wedges that the others called "lemon gunkies." But at four in the morning, anything tasted good. They would all watch as the program began to run, the lights going on, the whine from the speaker humming in high or low register depending on what was in Bit 14 in the accumulator, and the first thing he'd see on the CRT display after the program had been assembled and run was that the program had crashed. So he'd reach into the drawer for the tape with the FLIT debugger
and feed THAT into the computer. The computer would then be a debugging machine, and he'd send the program back in. Now he could start trying to find out where things had gone wrong, and maybe if he was lucky he'd find out, and change things by putting in some commands by flicking some of the switches on the console in precise order, or hammering in some code on the Flexowriter. Once things got running--and it was always incredibly satisfying when something worked, when he'd made that roomful of transistors and wires and metal and electricity all meld together to create a precise output that he'd devised--he'd try to add the next
advance to it. When the hour was over--someone already itching to get on the machine after him--Saunders would be ready to spend the next few hours figuring out what the heck had made the program go belly-up.
The peak hour itself was tremendously intense, but during the hours before, and even during the hours afterward, a hacker attained a state of pure concentration. When you programmed a computer, you had to be aware of where all the thousands of bits
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
25
of information were going from one instruction to the next, and be able to predict--and exploit--the effect of all that movement. When you had all that information glued to your cerebral being, it was almost as if your own mind had merged into the environment of the computer. Sometimes it took hours to build up to the
point where your thoughts could contain that total picture, and when you did get to that point, it was such a shame to waste it that you tried to sustain it by marathon bursts, alternatively working on the computer or poring over the code that you wrote on one of the off-line Flexowriters in the Kluge Room. You would sustain that concentration by "wrapping around" to the next day.
Inevitably, that frame of mind spilled over to what random shards of existence the hackers had outside of computing. The knife-and-paintbrush contingent at TMRC were not pleased at all by the infiltration of Tixo-mania into the club: they saw it as
a sort of Trojan horse for a switch in the club focus, from railroading to computing. And if you attended one of the club meetings held every Tuesday at five-fifteen, you could see the concern: the hackers would exploit every possible thread of parliamentary procedure to create a meeting as convoluted as the programs they were hacking on the TX-0. Motions were made to make motions to make motions, and objections ruled out of order as if they were so many computer errors. A note in the minutes of the meeting on November 24, 1959, suggests that "we frown on certain members who would do the club a lot more good by doing more S&P-ing and less reading Robert's Rules of Order." Samson was one of the worst offenders, and at one point, an exasperated TMRC member made a motion "to purchase a cork for Samson's oral diarrhea."
Hacking parliamentary procedure was one thing, but the logical mind-frame required for programming spilled over into more commonplace activities. You could ask a hacker a question and sense his mental accumulator processing bits until he came up with a precise answer to the question you asked. Marge Saunders would drive to the Safeway every Saturday morning in the Volkswagen and upon her return ask her husband, "Would you like to help me bring in the groceries?" Bob Saunders would reply, "No." Stunned, Marge would drag in the groceries herself. After the same thing occurred a few times, she exploded, hurling curses at him and demanding to know why he said no to her question.
"That's a stupid question to ask," he said. "Of course I won't LIKE to help you bring in the groceries. If you ask me if I'll help you bring them in, that's another matter."
It was as if Marge had submitted a program into the TX-0, and the program, as programs do when the syntax is improper, had crashed. It was not until she debugged her question that Bob Saunders would allow it to run successfully on his own mental computer.
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
26
CHAPTER 2 THE HACKER ETHIC
Something new was coalescing around the TX-0: a new way of life, with a philosophy, an ethic, and a dream.
There was no one moment when it started to dawn on the TX-0 hackers that by devoting their technical abilities to computing with a devotion rarely seen outside of monasteries they were the vanguard of a daring symbiosis between man and machine. With a fervor like that of young hot-rodders fixated on souping up
engines, they came to take their almost unique surroundings for granted, Even as the elements of a culture were forming, as legends began to accrue, as their mastery of programming started to surpass any previous recorded levels of skill, the dozen or so hackers were reluctant to acknowledge that their tiny society, on intimate terms with the TX-0, had been slowly and implicitly piecing together a body of concepts, beliefs, and mores.
The precepts of this revolutionary Hacker Ethic were not so much debated and discussed as silently agreed upon. No manifestos were issued. No missionaries tried to gather converts. The computer did the converting, and those who seemed to follow the Hacker Ethic most faithfully were people like Samson, Saunders, and Kotok, whose lives before MIT seemed to be mere preludes to that moment when they fulfilled themselves behind the console of the TX-0. Later there would come hackers who took the implicit Ethic even more seriously than the TX-0 hackers did, hackers like the legendary Greenblatt or Gosper, though it would be some years yet before the tenets of hackerism would be explicitly
delineated.
Still, even in the days of the TX-0, the planks of the platform were in place. The Hacker Ethic:
ACCESS TO COMPUTERS--AND ANYTHING WHICH MIGHT TEACH YOU SOMETHING ABOUT THE WAY THE WORLD WORKS--SHOULD BE UNLIMITED AND TOTAL. ALWAYS YIELD TO THE HANDS -ON IMPERATIVE!
Hackers believe that essential lessons can be learned about the systems--about the world--from taking things apart, seeing how they work, and using this knowledge to create new and even more interesting things. They resent any person, physical barrier, or law that tries to keep them from doing this.
This is especially true when a hacker wants to fix something that (from his point of view) is broken or needs improvement. Imperfect systems infuriate hackers, whose primal instinct is to debug them. This is one reason why hackers generally hate driving cars--the system of randomly programmed red lights and oddly laid out one-way streets causes delays which are so goddamned UNNECESSARY that the impulse is to rearrange signs, open up traffic-light control boxes . . .redesign the entire
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
27
system.
In a perfect hacker world, anyone pissed off enough to open up a control box near a traffic light and take it apart to make it work better should be perfectly welcome to make the attempt. Rules which prevent you from taking matters like that into your own hands are too ridiculous to even consider abiding by. This attitude helped the Model Railroad Club start, on an extremely informal basis, something called the Midnight Requisitioning Committee. When TMRC needed a set of diodes, or some extra relays, to build some new feature into The System, a few S&P people would wait until dark and find their way into the places where those things were kept. None of the hackers, who were as a rule scrupulously honest in other matters, seemed to equate this with "stealing." A willful blindness.
ALL INFORMATION SHOULD BE FREE.
If you don't have access to the information you need to improve things, how can you fix them? A free exchange of information particularly when the information was in the form of a computer program, allowed for greater overall creativity. When you were working on a machine like the TX-0, which came with almost no software, everyone would furiously write systems programs to make programming easier--Tools to Make Tools, kept in the drawer by the console for easy access by anyone using the machine. This prevented the dread, time-wasting ritual of reinventing the
wheel: instead of everybody writing his own version of the same program, the best version would be available to everyone, and everyone would be free to delve into the code and improve on THAT. A world studded with feature-full programs, bummed to the minimum, debugged to perfection.
The belief, sometimes taken unconditionally, that information should be free was a direct tribute to the way a splendid computer, or computer program, works--the binary bits moving in the most straightforward, logical path necessary to do their complex job, What was a computer but something which benefited from a free flow of information? If, say, the accumulator found itself unable to get information from the input/output (i/o)
devices like the tape reader or the switches, the whole system would collapse. In the hacker viewpoint, any system could benefit from that easy flow of information.
MISTRUST AUTHORITY--PROMOTE DECENTRALIZATION.
The best way to promote this free exchange of information is to have an open system, something which presents no boundaries between a hacker and a piece of information or an item of equipment that he needs in his quest for knowledge, improvement, and time on-line. The last thing you need is a bureaucracy. Bureaucracies, whether corporate, government, or university, are flawed systems, dangerous in that they cannot accommodate the
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
28
exploratory impulse of true hackers. Bureaucrats hide behind arbitrary rules (as opposed to the logical algorithms by which machines and computer programs operate): they invoke those rules to consolidate power, and perceive the constructive impulse of hackers as a threat.
The epitome of the bureaucratic world was to be found at a very large company called International Business Machines--IBM. The reason its computers were batch-processed Hulking Giants was only partially because of vacuum tube technology, The real reason was that IBM was a clumsy, hulking company which did not understand the hacking impulse. If IBM had its way (so the TMRC hackers thought), the world would be batch-processed, laid out on those annoying little punch cards, and only the most privileged of
priests would be permitted to actually interact with the computer.
All you had to do was look at someone in the IBM world, and note the button-down white shirt, the neatly pinned black tie, the hair carefully held in place, and the tray of punch cards in hand. You could wander into the Computation Center, where the 704, the 709, and later the 7090 were stored--the best IBM had to offer--and see the stifling orderliness, down to the roped-off areas beyond which non-authorized people could not venture. And you could compare that to the extremely informal atmosphere around the TX-0, where grungy clothes were the norm and almost anyone could wander in.
Now, IBM had done and would continue to do many things to advance computing. By its sheer size and mighty influence, it had made computers a permanent part of life in America. To many people, the words IBM and computer were virtually synonymous. IBM's machines were reliable workhorses, worthy of the trust that businessmen and scientists invested in them. This was due in
part to IBM's conservative approach: it would not make the most technologically advanced machines, but would rely on proven concepts and careful, aggressive marketing. As IBM's dominance of the computer field was established, the company became an empire unto itself, secretive and smug.
What really drove the hackers crazy was the attitude of the IBM priests and sub-priests, who seemed to think that IBM had the only "real" computers, and the rest were all trash. You couldn't talk to those people--they were beyond convincing. They were batch-processed people, and it showed not only in their preference of machines, but in their idea about the way a computation center, and a world, should be run. Those people could never understand the obvious superiority of a decentralized system, with no one giving orders: a system where people could follow their interests, and if along the way they discovered a
flaw in the system, they could embark on ambitious surgery. No need to get a requisition form. just a need to get something done.
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
29
This antibureaucratic bent coincided neatly with the personalities of many of the hackers, who since childhood had grown accustomed to building science projects while the rest of their classmates were banging their heads together and learning social skills on the field of sport. These young adults who were once outcasts found the computer a fantastic equalizer, experiencing a feeling, according to Peter Samson, "like you opened the door and walked through this grand new universe . . ." Once they passed through that door and sat behind the console of a million-dollar computer, hackers had power. So it was natural to distrust any force which might try to limit the extent of that power.
HACKERS SHOULD BE JUDGED BY THEIR HACKING, NOT BOGUS CRITERIA SUCH AS DEGREES, AGE, RACE, OR POSITION.
The ready acceptance of twelve-year-old Peter Deutsch in the TX-0 community (though not by non-hacker graduate students) was a good example. Likewise, people who trotted in with seemingly impressive credentials were not taken seriously until they proved themselves at the console of a computer. This meritocratic trait
was not necessarily rooted in the inherent goodness of hacker hearts--it was mainly that hackers cared less about someone's superficial characteristics than they did about his potential to advance the general state of hacking, to create new programs to admire, to talk about that new feature in the system.
YOU CAN CREATE ART AND BEAUTY ON A COMPUTER.
Samson's music program was an example. But to hackers, the art of the program did not reside in the pleasing sounds emanating from the on-line speaker. The code of the program held a beauty of its own. (Samson, though, was particularly obscure in
refusing to add comments to his source code explaining what he was doing at a given time. One well-distributed program Samson wrote went on for hundreds of assembly language instructions, with only one comment beside an instruction which contained the number 1750. The comment was RIPJSB, and people racked their brains about its meaning until someone figured out that 1750 was the year Bach died, and that Samson had written an abbreviation for Rest In Peace Johann Sebastian Bach.)
A certain esthetic of programming style had emerged. Because of the limited memory space of the TX-0 (a handicap that extended to all computers of that era), hackers came to deeply appreciate innovative techniques which allowed programs to do complicated tasks with very few instructions. The shorter a program was, the more space you had left for other programs, and the faster a program ran. Sometimes when you didn't need speed or space much, and you weren't thinking about art and beauty, you'd hack
together an ugly program, attacking the problem with "brute force" methods. "Well, we can do this by adding twenty numbers,"
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
30
Samson might say to himself, "and it's quicker to write instructions to do that than to think out a loop in the beginning and the end to do the same job in seven or eight instructions." But the latter program might be admired by fellow hackers, and some programs were bummed to the fewest lines so artfully that the author's peers would look at it and almost melt with awe.
Sometimes program bumming became competitive, a macho contest to prove oneself so much in command of the system that one could recognize elegant shortcuts to shave off an instruction or two, or, better yet, rethink the whole problem and devise a new
algorithm which would save a whole block of instructions. (An algorithm is a specific procedure which one can apply to solve a complex computer problem; it is sort of a mathematical skeleton key.) This could most emphatically be done by approaching the problem from an offbeat angle that no one had ever thought of before but that in retrospect made total sense. There was definitely an artistic impulse residing in those who could
utilize this genius-from-Mars techniques black-magic, visionary quality which enabled them to discard the stale outlook of the best minds on earth and come up with a totally unexpected new algorithm.
This happened with the decimal print routine program. This was a subroutines program within a program that you could sometimes integrate into many different programs--to translate binary numbers that the computer gave you into regular decimal numbers. In Saunders' words, this problem became the "pawn's ass of programming--if you could write a decimal print routine which worked you knew enough about the computer to call yourself a programmer of sorts." And if you wrote a GREAT decimal print routine, you might be able to call yourself a hacker. More than
a competition, the ultimate bumming of the decimal print routine became a sort of hacker Holy Grail.
Various versions of decimal print routines had been around for some months. If you were being deliberately stupid about it, or if you were a genuine moron--an out-and-out "loser"--it might take you a hundred instructions to get the computer to convert machine language to decimal. But any hacker worth his salt could do it in less, and finally, by taking the best of the programs, bumming an instruction here and there, the routine was diminished to about fifty instructions.
After that, things got serious. People would work for hours, seeking a way to do the same thing in fewer lines of code. It became more than a competition; it was a quest. For all the effort expended, no one seemed to be able to crack the fifty-line barrier. The question arose whether it was even possible to do it in less. Was there a point beyond which a program could not be bummed?
Among the people puzzling with this dilemma was a fellow named
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
31
Jenson, a tall, silent hacker from Maine who would sit quietly in the Kluge Room and scribble on printouts with the calm demeanor of a backwoodsman whittling. Jenson was always looking for ways to compress his programs in time and space--his code was a completely bizarre sequence of intermingled Boolean and arithmetic functions, often causing several different computations to occur in different sections of the same eighteen-bit "word." Amazing things, magical stunts.
Before Jenson, there had been general agreement that the only logical algorithm for a decimal print routine would have the machine repeatedly subtracting, using a table of the powers of ten to keep the numbers in proper digital columns. Jenson somehow figured that a powers-of-ten table wasn't necessary; he came up with an algorithm that was able to convert the digits in
a reverse order but, by some digital sleight of hand, print them out in the proper order. There was a complex mathematical justification to it that was clear to the other hackers only when they saw Jenson's program posted on a bulletin board, his way of telling them that he had taken the decimal print routine to its limit. FORTY-SIX INSTRUCTIONS. People would stare at the code and their jaws would drop. Marge Saunders remembers the hackers being unusually quiet for days afterward.
"We knew that was the end of it," Bob Saunders later said. "That was Nirvana."
COMPUTERS CAN CHANGE YOUR LIFE FOR THE BETTER.
This belief was subtly manifest. Rarely would a hacker try to impose a view of the myriad advantages of the computer way of knowledge to an outsider. Yet this premise dominated the everyday behavior of the TX-0 hackers, as well as the generations of hackers that came after them.
Surely the computer had changed THEIR lives, enriched their lives, given their lives focus, made their lives adventurous. It had made them masters of a certain slice of fate. Peter Samson later said, "We did it twenty-five to thirty percent for the sake
of doing it because it was something we could do and do well, and sixty percent for the sake of having something which was in its metaphorical way alive, our offspring, which would do things on its own when we were finished. That's the great thing about programming, the magical appeal it has . . . Once you fix a behavioral problem [a computer or program] has, it's fixed forever, and it is exactly an image of what you meant."
LIKE ALADDIN'S LAMP, YOU COULD GET IT TO DO YOUR BIDDING.
Surely everyone could benefit from experiencing this power. Surely everyone could benefit from a world based on the Hacker Ethic. This was the implicit belief of the hackers, and the hackers irreverently extended the conventional point of view of
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
32
what computers could and should do--leading the world to a new way of looking and interacting with computers.
This was not easily done. Even at such an advanced institution as MIT, some professors considered a manic affinity for computers as frivolous, even demented. TMRC hacker Bob Wagner once had to explain to an engineering professor what a computer was. Wagner experienced this clash of computer versus anti-computer even more vividly when he took a Numerical Analysis class in which the professor required each student to do homework using rattling, clunky electromechanical calculators. Kotok was in the same class, and both of them were appalled at the prospect of working with those lo-tech machines. "Why should we," they asked, "when we've got this computer?"
So Wagner began working on a computer program that would emulate the behavior of a calculator. The idea was outrageous. To some, it was a misappropriation of valuable machine time. According to the standard thinking on computers, their time was too precious
that one should only attempt things which took maximum advantage of the computer, things that otherwise would take roomfuls of mathematicians days of mindless calculating. Hackers felt otherwise: anything that seemed interesting or fun was fodder for computing--and using interactive computers, with no one looking over your shoulder and demanding clearance for your specific project, you could act on that belief. After two or three months
of tangling with intricacies of floating-point arithmetic (necessary to allow the program to know where to place the decimal point) on a machine that had no simple method to perform elementary multiplication, Wagner had written three thousand lines of code that did the job. He had made a ridiculously expensive computer perform the function of a calculator that cost a thousand times less. To honor this irony, he called the program Expensive Desk Calculator, and proudly did the homework for his class on it.
His grade--zero. "You used a computer!" the professor told him. "This CAN'T be right."
Wagner didn't even bother to explain. How could he convey to his teacher that the computer was making realities out of what were once incredible possibilities? Or that another hacker had even written a program called Expensive Typewriter that converted the TX-0 to something you could write text on, could process your writing in strings of characters and print it out on the Flexowriter--could you imagine a professor accepting a classwork report WRITTEN BY THE COMPUTER? How could that professor--how could, in fact, anyone who hadn't been immersed in this uncharted man-machine universe--understand how Wagner and his fellow hackers were routinely using the computer to simulate, according
to Wagner, "strange situations which one could scarcely envision otherwise"? The professor would learn in time, as would everyone, that the world opened up by the computer was a
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
33
limitless one.
If anyone needed further proof, you could cite the project that Kotok was working on in the Computation Center, the chess program that bearded Al professor "Uncle" John McCarthy, as he was becoming known to his hacker students, had begun on the IBM 704. Even though Kotok and the several other hackers helping him on the program had only contempt for the IBM batch-processing mentality that pervaded the machine and the people around it, they had managed to scrounge some late-night time to use it interactively, and had been engaging in an informal battle with the systems programmers on the 704 to see which group would be known as the biggest consumer of computer time. The lead would bounce back and forth, and the white-shirt-and-black-tie 704 people were impressed enough to actually let Kotok and his group touch the buttons and switches on the 704: rare sensual contact with a vaunted IBM beast.
Kotok's role in bringing the chess program to life was indicative of what was to become the hacker role in Artificial Intelligence: a Heavy Head like McCarthy or like his colleague Marvin Minsky would begin a project or wonder aloud whether something might be possible, and the hackers, if it interested them, would set about doing it.
The chess program had been started using FORTRAN, one of the early computer languages. Computer languages look more like English than assembly language, are easier to write with, and do more things with fewer instructions; however, each time an instruction is given in a computer language like FORTRAN, the computer must first translate that command into its own binary language. A program called a compiler does this, and the compiler takes up time to do its job, as well as occupying valuable space within the computer. In effect, using a computer language puts you an extra step away from direct contact with the computer, and hackers generally preferred assembly or, as they called it, "machine" language to less elegant, "higher-level" languages like FORTRAN.
Kotok, though, recognized that because of the huge amounts of numbers that would have to be crunched in a chess program, part of the program would have to be done in FORTRAN, and part in assembly. They hacked it part by part, with "move generators," basic data structures, and all kinds of innovative algorithms for strategy. After feeding the machine the rules for moving each piece, they gave it some parameters by which to evaluate its position, consider various moves, and make the move which would advance it to the most advantageous situation. Kotok kept at it for years, the program growing as MIT kept upgrading its IBM computers, and one memorable night a few hackers gathered to see the program make some of its first moves in a real game. Its opener was quite respectable, but after eight or so exchanges there was real trouble, with the computer about to be checkmated. Everybody
Get any book for free on: www.Abika.com
HACKERS, HEROES OF THE COMPUTER REVOLUTION
34
wondered how the computer would react. It too a while (everyone knew that during those pauses the computer was actually "thinking," if your idea of thinking included mechanically considering various moves, evaluating them, rejecting most, and using a predefined set of parameters to ultimately make a choice). Finally, the computer moved a pawn two squares forward--illegally jumping over another piece. A bug! But a clever one--it got the computer out of check. Maybe the program was figuring out some new algorithm with which to conquer chess.
At other universities, professors were making public proclamations that computers would never be able to beat a human being in chess. Hackers knew better. They would be the ones who would guide computers to greater heights than anyone expected. And the hackers, by fruitful, meaningful association with the computer, would be foremost among the beneficiaries.
But they would not be the only beneficiaries. Everyone could gain something by the use of thinking computers in an intellectually automated world. And wouldn't everyone benefit even more by approaching the world with the same inquisitive intensity, skepticism toward bureaucracy, openness to creativity, unselfishness in sharing accomplishments, urge to make improvements, and desire to build as those who followed the Hacker Ethic?
By accepting others on the same unprejudiced basis by which computers accepted anyone who entered code into a Flexowriter? Wouldn't we benefit if we learned from computers the means of creating a perfect system? If EVERYONE could interact with computers with the same innocent, productive, creative impulse that hackers did, the Hacker Ethic might spread through society like a benevolent ripple, and computers would indeed change
the world for the better.
In the monastic confines of the Massachusetts Institute of Technology, people had the freedom to live out this dream--the hacker dream. No one dared suggest that the dream might spread. Instead, people set about building, right there at MIT, a hacker Xanadu the likes
of which might never be duplicated.



